{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "22ffe200",
      "metadata": {},
      "source": [
        "# EN-AR Model Training\n",
        "\n",
        "## Objective\n",
        "- Train a bidirectional EN <-> AR encoder-decoder model from random initialization.\n",
        "- Use the cleaned combined dataset exported by Notebook 01.\n",
        "\n",
        "## Scope\n",
        "- Notebook-first, micro-step implementation (1-2 short cells per step).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "a1d5f8ca",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"PATH\"] = r\"C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.44.35207\\bin\\Hostx64\\x64\" + os.pathsep + os.environ.get(\"PATH\", \"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "c46cad66",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Project root: c:\\My Projects\\en-ar-translation\n",
            "Dataset path: c:\\My Projects\\en-ar-translation\\artifacts\\eda\\final_cleaned_combined_dataset.parquet\n",
            "CUDA available: True\n",
            "TrainConfig(max_seq_len=128, vocab_size=32000, train_ratio=0.9, val_ratio=0.05, test_ratio=0.05)\n"
          ]
        }
      ],
      "source": [
        "# Setup: imports and training constants\n",
        "from __future__ import annotations\n",
        "\n",
        "from dataclasses import dataclass\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "\n",
        "RANDOM_SEED = 42\n",
        "np.random.seed(RANDOM_SEED)\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "\n",
        "candidate_roots = [Path.cwd(), Path.cwd().parent]\n",
        "PROJECT_ROOT = next((r for r in candidate_roots if (r / \"artifacts\").exists()), Path.cwd())\n",
        "DATA_PATH = PROJECT_ROOT / \"artifacts\" / \"eda\" / \"final_cleaned_combined_dataset.parquet\"\n",
        "\n",
        "@dataclass\n",
        "class TrainConfig:\n",
        "    max_seq_len: int = 128\n",
        "    vocab_size: int = 32_000\n",
        "    train_ratio: float = 0.90\n",
        "    val_ratio: float = 0.05\n",
        "    test_ratio: float = 0.05\n",
        "\n",
        "config = TrainConfig()\n",
        "print(f\"Project root: {PROJECT_ROOT}\")\n",
        "print(f\"Dataset path: {DATA_PATH}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "print(config)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "caa92828",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded dataset: c:\\My Projects\\en-ar-translation\\artifacts\\eda\\final_cleaned_combined_dataset.parquet\n",
            "Shape: (827576, 2)\n",
            "Columns: ['en', 'ar']\n"
          ]
        }
      ],
      "source": [
        "# Micro-step 2: load cleaned dataset and validate schema\n",
        "assert DATA_PATH.exists(), f\"Cleaned dataset not found: {DATA_PATH}\"\n",
        "df = pd.read_parquet(DATA_PATH)\n",
        "\n",
        "required_columns = [\"en\", \"ar\"]\n",
        "missing = [c for c in required_columns if c not in df.columns]\n",
        "assert not missing, f\"Missing required columns: {missing}\"\n",
        "\n",
        "print(f\"Loaded dataset: {DATA_PATH}\")\n",
        "print(f\"Shape: {df.shape}\")\n",
        "print(f\"Columns: {list(df.columns)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "c6e9cec1",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Rows before cleaning: 827,576\n",
            "Rows after cleaning: 827,546\n",
            "Rows removed: 30\n"
          ]
        }
      ],
      "source": [
        "# Micro-step 3: remove invalid/empty rows and report before/after\n",
        "rows_before = len(df)\n",
        "\n",
        "df = df.dropna(subset=[\"en\", \"ar\"]).copy()\n",
        "df[\"en\"] = df[\"en\"].astype(str).str.strip()\n",
        "df[\"ar\"] = df[\"ar\"].astype(str).str.strip()\n",
        "df = df[(df[\"en\"] != \"\") & (df[\"ar\"] != \"\")].reset_index(drop=True)\n",
        "\n",
        "rows_after = len(df)\n",
        "rows_removed = rows_before - rows_after\n",
        "print(f\"Rows before cleaning: {rows_before:,}\")\n",
        "print(f\"Rows after cleaning: {rows_after:,}\")\n",
        "print(f\"Rows removed: {rows_removed:,}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "5032acd3",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>en</th>\n",
              "      <th>ar</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>man with blue shirt standing in a gymnasium</td>\n",
              "      <td>رجل ذو قميص أزرق يقف في صالة رياضية</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Hart did not run for public office again.</td>\n",
              "      <td>لم تبحث شركة Hart عن مقر عام لها مجددا.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>uh present day linda ronstadt</td>\n",
              "      <td>في الوقت الحاضر (ليندا رونستد)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The current mayor is Leonard Reed.</td>\n",
              "      <td>ليونارد ريد هو عمدة البلدية الحالي.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\"It's for Annabelle.\"</td>\n",
              "      <td>إنها لأنابيل.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>thats not your problem</td>\n",
              "      <td>هذه ليست مشكلتك</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>leave me alone</td>\n",
              "      <td>كلا ! دعوني وشأني</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>a large silver filigree pendant on a white bac...</td>\n",
              "      <td>قلادة فضية كبيرة على خلفية بيضاء</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>a large brick building with a blue sign that r...</td>\n",
              "      <td>مبنى كبير من الطوب مع علامة زرقاء التي تقرأ'mo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>egyptian president muhammad morsi has started ...</td>\n",
              "      <td>بدا الرييس المصري محمد مرسي رسميا بالتغريد عبر...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  en  \\\n",
              "0        man with blue shirt standing in a gymnasium   \n",
              "1          Hart did not run for public office again.   \n",
              "2                      uh present day linda ronstadt   \n",
              "3                 The current mayor is Leonard Reed.   \n",
              "4                              \"It's for Annabelle.\"   \n",
              "5                             thats not your problem   \n",
              "6                                     leave me alone   \n",
              "7  a large silver filigree pendant on a white bac...   \n",
              "8  a large brick building with a blue sign that r...   \n",
              "9  egyptian president muhammad morsi has started ...   \n",
              "\n",
              "                                                  ar  \n",
              "0                رجل ذو قميص أزرق يقف في صالة رياضية  \n",
              "1            لم تبحث شركة Hart عن مقر عام لها مجددا.  \n",
              "2                     في الوقت الحاضر (ليندا رونستد)  \n",
              "3                ليونارد ريد هو عمدة البلدية الحالي.  \n",
              "4                                      إنها لأنابيل.  \n",
              "5                                    هذه ليست مشكلتك  \n",
              "6                                  كلا ! دعوني وشأني  \n",
              "7                   قلادة فضية كبيرة على خلفية بيضاء  \n",
              "8  مبنى كبير من الطوب مع علامة زرقاء التي تقرأ'mo...  \n",
              "9  بدا الرييس المصري محمد مرسي رسميا بالتغريد عبر...  "
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Quick check: 10 random rows from current dataset\n",
        "df.sample(n=10)[[\"en\", \"ar\"]].reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "f1f6f191",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>split</th>\n",
              "      <th>rows</th>\n",
              "      <th>ratio</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>train</td>\n",
              "      <td>744926</td>\n",
              "      <td>0.9002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>val</td>\n",
              "      <td>41445</td>\n",
              "      <td>0.0501</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>test</td>\n",
              "      <td>41175</td>\n",
              "      <td>0.0498</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   split    rows   ratio\n",
              "0  train  744926  0.9002\n",
              "1    val   41445  0.0501\n",
              "2   test   41175  0.0498"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Micro-step 4: deterministic hash split (90/5/5) with leakage guard\n",
        "assert abs((config.train_ratio + config.val_ratio + config.test_ratio) - 1.0) < 1e-9, \"Split ratios must sum to 1.0\"\n",
        "\n",
        "pair_hash = pd.util.hash_pandas_object(df[[\"en\", \"ar\"]], index=False).astype(\"uint64\")\n",
        "u = pair_hash / np.float64(2**64)\n",
        "\n",
        "train_cut = config.train_ratio\n",
        "val_cut = config.train_ratio + config.val_ratio\n",
        "df[\"split\"] = np.where(u < train_cut, \"train\", np.where(u < val_cut, \"val\", \"test\"))\n",
        "\n",
        "leak_count = int((df.groupby([\"en\", \"ar\"])[\"split\"].nunique() > 1).sum())\n",
        "assert leak_count == 0, f\"Leakage detected across splits for {leak_count} pairs\"\n",
        "\n",
        "split_counts = df[\"split\"].value_counts().rename_axis(\"split\").reset_index(name=\"rows\")\n",
        "split_counts[\"ratio\"] = (split_counts[\"rows\"] / len(df)).round(4)\n",
        "split_counts\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "97237a4c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Base rows: 827,546\n",
            "Bidirectional rows: 1,655,092\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>split</th>\n",
              "      <th>direction</th>\n",
              "      <th>rows</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>test</td>\n",
              "      <td>ar_to_en</td>\n",
              "      <td>41175</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>test</td>\n",
              "      <td>en_to_ar</td>\n",
              "      <td>41175</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>train</td>\n",
              "      <td>ar_to_en</td>\n",
              "      <td>744926</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>train</td>\n",
              "      <td>en_to_ar</td>\n",
              "      <td>744926</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>val</td>\n",
              "      <td>ar_to_en</td>\n",
              "      <td>41445</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>val</td>\n",
              "      <td>en_to_ar</td>\n",
              "      <td>41445</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   split direction    rows\n",
              "0   test  ar_to_en   41175\n",
              "1   test  en_to_ar   41175\n",
              "2  train  ar_to_en  744926\n",
              "3  train  en_to_ar  744926\n",
              "4    val  ar_to_en   41445\n",
              "5    val  en_to_ar   41445"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Micro-step 5: build bidirectional rows with direction tokens\n",
        "required_split_cols = [\"en\", \"ar\", \"split\"]\n",
        "missing_split_cols = [c for c in required_split_cols if c not in df.columns]\n",
        "assert not missing_split_cols, f\"Missing columns before bidirectional build: {missing_split_cols}\"\n",
        "\n",
        "df_en_to_ar = pd.DataFrame({\n",
        "    \"source_text\": \"<2ar> \" + df[\"en\"],\n",
        "    \"target_text\": df[\"ar\"],\n",
        "    \"direction\": \"en_to_ar\",\n",
        "    \"split\": df[\"split\"],\n",
        "})\n",
        "\n",
        "df_ar_to_en = pd.DataFrame({\n",
        "    \"source_text\": \"<2en> \" + df[\"ar\"],\n",
        "    \"target_text\": df[\"en\"],\n",
        "    \"direction\": \"ar_to_en\",\n",
        "    \"split\": df[\"split\"],\n",
        "})\n",
        "\n",
        "df_bi = pd.concat([df_en_to_ar, df_ar_to_en], ignore_index=True)\n",
        "\n",
        "print(f\"Base rows: {len(df):,}\")\n",
        "print(f\"Bidirectional rows: {len(df_bi):,}\")\n",
        "\n",
        "direction_split_counts = (\n",
        "    df_bi.groupby([\"split\", \"direction\"]).size().reset_index(name=\"rows\")\n",
        ")\n",
        "direction_split_counts\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "89f344a6",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train rows: 1,489,852\n",
            "val rows: 82,890\n",
            "test rows: 82,350\n"
          ]
        }
      ],
      "source": [
        "# Micro-step 6: create train/val/test views from bidirectional dataset\n",
        "required_bi_cols = [\"source_text\", \"target_text\", \"direction\", \"split\"]\n",
        "missing_bi_cols = [c for c in required_bi_cols if c not in df_bi.columns]\n",
        "assert not missing_bi_cols, f\"Missing columns in df_bi: {missing_bi_cols}\"\n",
        "\n",
        "train_df = df_bi[df_bi[\"split\"] == \"train\"].reset_index(drop=True)\n",
        "val_df = df_bi[df_bi[\"split\"] == \"val\"].reset_index(drop=True)\n",
        "test_df = df_bi[df_bi[\"split\"] == \"test\"].reset_index(drop=True)\n",
        "\n",
        "assert len(train_df) + len(val_df) + len(test_df) == len(df_bi), \"Split size mismatch\"\n",
        "assert len(train_df) > 0 and len(val_df) > 0 and len(test_df) > 0, \"One split is empty\"\n",
        "\n",
        "print(f\"train rows: {len(train_df):,}\")\n",
        "print(f\"val rows: {len(val_df):,}\")\n",
        "print(f\"test rows: {len(test_df):,}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "78765424",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tokenizer output path: c:\\My Projects\\en-ar-translation\\artifacts\\tokenizer\\en_ar_bpe_tokenizer.json\n",
            "Special tokens: ['<pad>', '<s>', '</s>', '<unk>', '<2ar>', '<2en>']\n",
            "Tokenizer mode: ByteLevel BPE\n",
            "Train rows for tokenizer: 1,489,852\n",
            "Approx lines seen by tokenizer iterator: 2,979,704\n"
          ]
        }
      ],
      "source": [
        "# Micro-step 7: tokenizer setup (train split only)\n",
        "try:\n",
        "    from tokenizers import Tokenizer, decoders, models, pre_tokenizers, trainers\n",
        "except ImportError as e:\n",
        "    raise ImportError(\"`tokenizers` is required. Install with: pip install tokenizers\") from e\n",
        "\n",
        "TOKENIZER_DIR = PROJECT_ROOT / \"artifacts\" / \"tokenizer\"\n",
        "TOKENIZER_DIR.mkdir(parents=True, exist_ok=True)\n",
        "TOKENIZER_PATH = TOKENIZER_DIR / \"en_ar_bpe_tokenizer.json\"\n",
        "\n",
        "SPECIAL_TOKENS = [\"<pad>\", \"<s>\", \"</s>\", \"<unk>\", \"<2ar>\", \"<2en>\"]\n",
        "\n",
        "def train_corpus_iterator(df_in):\n",
        "    for row in df_in.itertuples(index=False):\n",
        "        yield row.source_text\n",
        "        yield row.target_text\n",
        "\n",
        "print(f\"Tokenizer output path: {TOKENIZER_PATH}\")\n",
        "print(f\"Special tokens: {SPECIAL_TOKENS}\")\n",
        "print(\"Tokenizer mode: ByteLevel BPE\")\n",
        "print(f\"Train rows for tokenizer: {len(train_df):,}\")\n",
        "print(f\"Approx lines seen by tokenizer iterator: {len(train_df) * 2:,}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "4cb5dac7",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trained tokenizer vocab size: 32,000\n",
            "Saved tokenizer to: c:\\My Projects\\en-ar-translation\\artifacts\\tokenizer\\en_ar_bpe_tokenizer.json\n"
          ]
        }
      ],
      "source": [
        "# Micro-step 8: train and save shared ByteLevel BPE tokenizer\n",
        "tokenizer = Tokenizer(models.BPE(unk_token=\"<unk>\"))\n",
        "tokenizer.pre_tokenizer = pre_tokenizers.ByteLevel(add_prefix_space=False)\n",
        "tokenizer.decoder = decoders.ByteLevel()\n",
        "\n",
        "trainer = trainers.BpeTrainer(\n",
        "    vocab_size=config.vocab_size,\n",
        "    special_tokens=SPECIAL_TOKENS,\n",
        "    min_frequency=2,\n",
        "    initial_alphabet=pre_tokenizers.ByteLevel.alphabet(),\n",
        ")\n",
        "\n",
        "tokenizer.train_from_iterator(train_corpus_iterator(train_df), trainer=trainer)\n",
        "tokenizer.save(str(TOKENIZER_PATH))\n",
        "\n",
        "vocab_size_trained = tokenizer.get_vocab_size()\n",
        "print(f\"Trained tokenizer vocab size: {vocab_size_trained:,}\")\n",
        "print(f\"Saved tokenizer to: {TOKENIZER_PATH}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "c7e854cc",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Special token IDs: {'<pad>': 0, '<s>': 1, '</s>': 2, '<unk>': 3, '<2ar>': 4, '<2en>': 5}\n",
            "Direction token probes OK (<2ar>/<2en> preserved).\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>metric</th>\n",
              "      <th>value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>sample_rows</td>\n",
              "      <td>20000.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>trained_vocab_size</td>\n",
              "      <td>32000.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>src_len_p50</td>\n",
              "      <td>9.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>src_len_p90</td>\n",
              "      <td>18.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>src_len_p95</td>\n",
              "      <td>21.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>src_len_p99</td>\n",
              "      <td>28.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>tgt_len_p50</td>\n",
              "      <td>8.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>tgt_len_p90</td>\n",
              "      <td>17.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>tgt_len_p95</td>\n",
              "      <td>20.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>tgt_len_p99</td>\n",
              "      <td>28.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>src_trunc_ratio_gt_max_len</td>\n",
              "      <td>0.0001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>tgt_trunc_ratio_gt_max_len</td>\n",
              "      <td>0.0001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>either_trunc_ratio_gt_max_len</td>\n",
              "      <td>0.0002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>src_unk_tokens</td>\n",
              "      <td>0.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>tgt_unk_tokens</td>\n",
              "      <td>0.0000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                           metric       value\n",
              "0                     sample_rows  20000.0000\n",
              "1              trained_vocab_size  32000.0000\n",
              "2                     src_len_p50      9.0000\n",
              "3                     src_len_p90     18.0000\n",
              "4                     src_len_p95     21.0000\n",
              "5                     src_len_p99     28.0000\n",
              "6                     tgt_len_p50      8.0000\n",
              "7                     tgt_len_p90     17.0000\n",
              "8                     tgt_len_p95     20.0000\n",
              "9                     tgt_len_p99     28.0000\n",
              "10     src_trunc_ratio_gt_max_len      0.0001\n",
              "11     tgt_trunc_ratio_gt_max_len      0.0001\n",
              "12  either_trunc_ratio_gt_max_len      0.0002\n",
              "13                 src_unk_tokens      0.0000\n",
              "14                 tgt_unk_tokens      0.0000"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Micro-step 9: tokenizer audit (critical checks)\n",
        "from collections import Counter\n",
        "\n",
        "# Ensure tokenizer object is available (reload from disk if needed)\n",
        "if \"tokenizer\" not in globals():\n",
        "    tokenizer = Tokenizer.from_file(str(TOKENIZER_PATH))\n",
        "\n",
        "# 1) Special-token integrity\n",
        "special_token_ids = {tok: tokenizer.token_to_id(tok) for tok in SPECIAL_TOKENS}\n",
        "missing_special = [tok for tok, tid in special_token_ids.items() if tid is None]\n",
        "assert not missing_special, f\"Missing special tokens in tokenizer vocab: {missing_special}\"\n",
        "\n",
        "id_2ar = special_token_ids[\"<2ar>\"]\n",
        "id_2en = special_token_ids[\"<2en>\"]\n",
        "probe_2ar = tokenizer.encode(\"<2ar> this is a test\")\n",
        "probe_2en = tokenizer.encode(\"<2en> english direction probe\")\n",
        "assert len(probe_2ar.ids) > 0 and probe_2ar.ids[0] == id_2ar, \"<2ar> is not preserved as first token\"\n",
        "assert len(probe_2en.ids) > 0 and probe_2en.ids[0] == id_2en, \"<2en> is not preserved as first token\"\n",
        "\n",
        "# 2) Sample-based token-length and truncation audit (real tokenizer lengths)\n",
        "audit_sample_size = min(20000, len(df_bi))\n",
        "audit_df = df_bi.sample(n=audit_sample_size, random_state=RANDOM_SEED) if len(df_bi) > audit_sample_size else df_bi\n",
        "\n",
        "src_lengths = []\n",
        "tgt_lengths = []\n",
        "unk_counter = Counter()\n",
        "unk_id = special_token_ids[\"<unk>\"]\n",
        "\n",
        "for row in audit_df.itertuples(index=False):\n",
        "    src_ids = tokenizer.encode(row.source_text).ids\n",
        "    tgt_ids = tokenizer.encode(row.target_text).ids\n",
        "    src_lengths.append(len(src_ids))\n",
        "    tgt_lengths.append(len(tgt_ids))\n",
        "    unk_counter[\"src_unk_tokens\"] += sum(1 for i in src_ids if i == unk_id)\n",
        "    unk_counter[\"tgt_unk_tokens\"] += sum(1 for i in tgt_ids if i == unk_id)\n",
        "\n",
        "src_lengths = np.array(src_lengths, dtype=np.int32)\n",
        "tgt_lengths = np.array(tgt_lengths, dtype=np.int32)\n",
        "\n",
        "tokenizer_audit = pd.DataFrame({\n",
        "    \"metric\": [\n",
        "        \"sample_rows\",\n",
        "        \"trained_vocab_size\",\n",
        "        \"src_len_p50\", \"src_len_p90\", \"src_len_p95\", \"src_len_p99\",\n",
        "        \"tgt_len_p50\", \"tgt_len_p90\", \"tgt_len_p95\", \"tgt_len_p99\",\n",
        "        \"src_trunc_ratio_gt_max_len\",\n",
        "        \"tgt_trunc_ratio_gt_max_len\",\n",
        "        \"either_trunc_ratio_gt_max_len\",\n",
        "        \"src_unk_tokens\",\n",
        "        \"tgt_unk_tokens\",\n",
        "    ],\n",
        "    \"value\": [\n",
        "        int(len(audit_df)),\n",
        "        int(tokenizer.get_vocab_size()),\n",
        "        int(np.percentile(src_lengths, 50)), int(np.percentile(src_lengths, 90)), int(np.percentile(src_lengths, 95)), int(np.percentile(src_lengths, 99)),\n",
        "        int(np.percentile(tgt_lengths, 50)), int(np.percentile(tgt_lengths, 90)), int(np.percentile(tgt_lengths, 95)), int(np.percentile(tgt_lengths, 99)),\n",
        "        float((src_lengths > config.max_seq_len).mean()),\n",
        "        float((tgt_lengths > config.max_seq_len).mean()),\n",
        "        float(((src_lengths > config.max_seq_len) | (tgt_lengths > config.max_seq_len)).mean()),\n",
        "        int(unk_counter[\"src_unk_tokens\"]),\n",
        "        int(unk_counter[\"tgt_unk_tokens\"]),\n",
        "    ]\n",
        "})\n",
        "\n",
        "print(\"Special token IDs:\", special_token_ids)\n",
        "print(\"Direction token probes OK (<2ar>/<2en> preserved).\")\n",
        "tokenizer_audit\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "5ff47333",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved HF tokenizer to: c:\\My Projects\\en-ar-translation\\artifacts\\tokenizer\\hf_tokenizer\n",
            "Token IDs: {'<pad>': 0, '<s>': 1, '</s>': 2, '<unk>': 3, '<2ar>': 4, '<2en>': 5}\n",
            "HF vocab size: 32,000\n"
          ]
        }
      ],
      "source": [
        "# Micro-step 10: build and save Hugging Face compatible fast tokenizer\n",
        "from transformers import PreTrainedTokenizerFast\n",
        "\n",
        "HF_TOKENIZER_DIR = TOKENIZER_DIR / \"hf_tokenizer\"\n",
        "HF_TOKENIZER_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "hf_tokenizer = PreTrainedTokenizerFast(\n",
        "    tokenizer_file=str(TOKENIZER_PATH),\n",
        "    bos_token=\"<s>\",\n",
        "    eos_token=\"</s>\",\n",
        "    unk_token=\"<unk>\",\n",
        "    pad_token=\"<pad>\",\n",
        "    additional_special_tokens=[\"<2ar>\", \"<2en>\"],\n",
        ")\n",
        "\n",
        "# Verify essential token ids exist\n",
        "required_tokens = [\"<pad>\", \"<s>\", \"</s>\", \"<unk>\", \"<2ar>\", \"<2en>\"]\n",
        "token_id_map = {tok: hf_tokenizer.convert_tokens_to_ids(tok) for tok in required_tokens}\n",
        "missing_ids = [tok for tok, tid in token_id_map.items() if tid is None or tid < 0]\n",
        "assert not missing_ids, f\"Missing token ids in hf_tokenizer: {missing_ids}\"\n",
        "\n",
        "hf_tokenizer.save_pretrained(str(HF_TOKENIZER_DIR))\n",
        "\n",
        "print(f\"Saved HF tokenizer to: {HF_TOKENIZER_DIR}\")\n",
        "print(\"Token IDs:\", token_id_map)\n",
        "print(f\"HF vocab size: {hf_tokenizer.vocab_size:,}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "21169324",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c6cfab8e2fe34823985778e0b18e2601",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Tokenizing train:   0%|          | 0/1489852 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "90aadf24974b46a7b6cd1466d84fc2c3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Tokenizing val:   0%|          | 0/82890 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a2e9e442391c4b77be7db8142fa914c5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Tokenizing test:   0%|          | 0/82350 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tokenized train rows: 1,489,852\n",
            "Tokenized val rows: 82,890\n",
            "Tokenized test rows: 82,350\n",
            "dict_keys(['source_text', 'target_text', 'direction', 'split', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n"
          ]
        }
      ],
      "source": [
        "# Micro-step 11: tokenize train/val/test (truncation only, no static padding)\n",
        "from datasets import Dataset\n",
        "\n",
        "def tokenize_batch(batch):\n",
        "    src = hf_tokenizer(\n",
        "        batch[\"source_text\"],\n",
        "        truncation=True,\n",
        "        max_length=config.max_seq_len,\n",
        "        padding=False,\n",
        "    )\n",
        "    tgt = hf_tokenizer(\n",
        "        batch[\"target_text\"],\n",
        "        truncation=True,\n",
        "        max_length=config.max_seq_len,\n",
        "        padding=False,\n",
        "    )\n",
        "    src[\"labels\"] = tgt[\"input_ids\"]\n",
        "    return src\n",
        "\n",
        "train_ds = Dataset.from_pandas(train_df[[\"source_text\", \"target_text\", \"direction\", \"split\"]], preserve_index=False)\n",
        "val_ds = Dataset.from_pandas(val_df[[\"source_text\", \"target_text\", \"direction\", \"split\"]], preserve_index=False)\n",
        "test_ds = Dataset.from_pandas(test_df[[\"source_text\", \"target_text\", \"direction\", \"split\"]], preserve_index=False)\n",
        "\n",
        "train_tok = train_ds.map(tokenize_batch, batched=True, desc=\"Tokenizing train\")\n",
        "val_tok = val_ds.map(tokenize_batch, batched=True, desc=\"Tokenizing val\")\n",
        "test_tok = test_ds.map(tokenize_batch, batched=True, desc=\"Tokenizing test\")\n",
        "\n",
        "print(f\"Tokenized train rows: {len(train_tok):,}\")\n",
        "print(f\"Tokenized val rows: {len(val_tok):,}\")\n",
        "print(f\"Tokenized test rows: {len(test_tok):,}\")\n",
        "print(train_tok[0].keys())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "b4c5041c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Probe batch size: 32\n",
            "input_ids shape: (32, 74)\n",
            "attention_mask shape: (32, 74)\n",
            "labels shape: (32, 37)\n",
            "Dynamic padded source length (batch max): 74\n",
            "Dynamic padded target length (batch max): 37\n",
            "Configured truncation cap: 128\n"
          ]
        }
      ],
      "source": [
        "# Micro-step 12: dynamic padding collator + one-batch sanity check\n",
        "from transformers import DataCollatorForSeq2Seq\n",
        "\n",
        "model_input_cols = [\"input_ids\", \"attention_mask\", \"labels\"]\n",
        "train_tok_model = train_tok.remove_columns([c for c in train_tok.column_names if c not in model_input_cols])\n",
        "\n",
        "data_collator = DataCollatorForSeq2Seq(\n",
        "    tokenizer=hf_tokenizer,\n",
        "    model=None,\n",
        "    padding=\"longest\",\n",
        "    label_pad_token_id=-100,\n",
        ")\n",
        "\n",
        "batch_size_probe = min(32, len(train_tok_model))\n",
        "probe_ds = train_tok_model.shuffle(seed=RANDOM_SEED).select(range(batch_size_probe))\n",
        "probe_features = [probe_ds[i] for i in range(len(probe_ds))]\n",
        "probe_batch = data_collator(probe_features)\n",
        "\n",
        "print(f\"Probe batch size: {batch_size_probe}\")\n",
        "print(f\"input_ids shape: {tuple(probe_batch['input_ids'].shape)}\")\n",
        "print(f\"attention_mask shape: {tuple(probe_batch['attention_mask'].shape)}\")\n",
        "print(f\"labels shape: {tuple(probe_batch['labels'].shape)}\")\n",
        "print(f\"Dynamic padded source length (batch max): {probe_batch['input_ids'].shape[1]}\")\n",
        "print(f\"Dynamic padded target length (batch max): {probe_batch['labels'].shape[1]}\")\n",
        "print(f\"Configured truncation cap: {config.max_seq_len}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "59accefc",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>direction</th>\n",
              "      <th>source_text</th>\n",
              "      <th>target_text</th>\n",
              "      <th>source_len</th>\n",
              "      <th>target_len</th>\n",
              "      <th>source_ids</th>\n",
              "      <th>target_ids</th>\n",
              "      <th>decoded_source_from_ids</th>\n",
              "      <th>decoded_target_from_ids</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ar_to_en</td>\n",
              "      <td>&lt;2en&gt; فقد نفذ مني البروبان تقريبا</td>\n",
              "      <td>im nearly out of propane</td>\n",
              "      <td>7</td>\n",
              "      <td>6</td>\n",
              "      <td>[5, 3071, 18650, 4714, 1520, 16742, 4348]</td>\n",
              "      <td>[431, 9763, 684, 333, 4298, 2385]</td>\n",
              "      <td>&lt;2en&gt; فقد نفذ مني البروبان تقريبا</td>\n",
              "      <td>im nearly out of propane</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>en_to_ar</td>\n",
              "      <td>&lt;2ar&gt; another glass for the lady</td>\n",
              "      <td>أتريدين كأسا آخر؟</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>[4, 2200, 1849, 434, 295, 5523]</td>\n",
              "      <td>[27912, 17415, 1714, 411]</td>\n",
              "      <td>&lt;2ar&gt; another glass for the lady</td>\n",
              "      <td>أتريدين كأسا آخر؟</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ar_to_en</td>\n",
              "      <td>&lt;2en&gt; أنت مضحك</td>\n",
              "      <td>mm youre funny</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>[5, 895, 10872]</td>\n",
              "      <td>[3683, 1151, 5910]</td>\n",
              "      <td>&lt;2en&gt; أنت مضحك</td>\n",
              "      <td>mm youre funny</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ar_to_en</td>\n",
              "      <td>&lt;2en&gt; رغم ذلك، فإن هذه المعتقدات لها ما يبررها...</td>\n",
              "      <td>However, these beliefs are clearly justified.</td>\n",
              "      <td>17</td>\n",
              "      <td>10</td>\n",
              "      <td>[5, 10193, 569, 360, 3970, 687, 332, 1144, 335...</td>\n",
              "      <td>[3799, 17, 1614, 18768, 88, 450, 13120, 798, 4...</td>\n",
              "      <td>&lt;2en&gt; رغم ذلك، فإن هذه المعتقدات لها ما يبررها...</td>\n",
              "      <td>However, these beliefs are clearly justified.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ar_to_en</td>\n",
              "      <td>&lt;2en&gt; قراءة والمشاركة في مدونة الاصوات الصاعدة...</td>\n",
              "      <td>read and participate on the rising voices blog...</td>\n",
              "      <td>39</td>\n",
              "      <td>35</td>\n",
              "      <td>[5, 10144, 1723, 12101, 325, 7438, 2178, 29307...</td>\n",
              "      <td>[4776, 355, 18161, 372, 295, 13727, 2129, 2799...</td>\n",
              "      <td>&lt;2en&gt; قراءة والمشاركة في مدونة الاصوات الصاعدة...</td>\n",
              "      <td>read and participate on the rising voices blog...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  direction                                        source_text  \\\n",
              "0  ar_to_en                  <2en> فقد نفذ مني البروبان تقريبا   \n",
              "1  en_to_ar                   <2ar> another glass for the lady   \n",
              "2  ar_to_en                                     <2en> أنت مضحك   \n",
              "3  ar_to_en  <2en> رغم ذلك، فإن هذه المعتقدات لها ما يبررها...   \n",
              "4  ar_to_en  <2en> قراءة والمشاركة في مدونة الاصوات الصاعدة...   \n",
              "\n",
              "                                         target_text  source_len  target_len  \\\n",
              "0                           im nearly out of propane           7           6   \n",
              "1                                  أتريدين كأسا آخر؟           6           4   \n",
              "2                                     mm youre funny           3           3   \n",
              "3      However, these beliefs are clearly justified.          17          10   \n",
              "4  read and participate on the rising voices blog...          39          35   \n",
              "\n",
              "                                          source_ids  \\\n",
              "0          [5, 3071, 18650, 4714, 1520, 16742, 4348]   \n",
              "1                    [4, 2200, 1849, 434, 295, 5523]   \n",
              "2                                    [5, 895, 10872]   \n",
              "3  [5, 10193, 569, 360, 3970, 687, 332, 1144, 335...   \n",
              "4  [5, 10144, 1723, 12101, 325, 7438, 2178, 29307...   \n",
              "\n",
              "                                          target_ids  \\\n",
              "0                  [431, 9763, 684, 333, 4298, 2385]   \n",
              "1                          [27912, 17415, 1714, 411]   \n",
              "2                                 [3683, 1151, 5910]   \n",
              "3  [3799, 17, 1614, 18768, 88, 450, 13120, 798, 4...   \n",
              "4  [4776, 355, 18161, 372, 295, 13727, 2129, 2799...   \n",
              "\n",
              "                             decoded_source_from_ids  \\\n",
              "0                  <2en> فقد نفذ مني البروبان تقريبا   \n",
              "1                   <2ar> another glass for the lady   \n",
              "2                                     <2en> أنت مضحك   \n",
              "3  <2en> رغم ذلك، فإن هذه المعتقدات لها ما يبررها...   \n",
              "4  <2en> قراءة والمشاركة في مدونة الاصوات الصاعدة...   \n",
              "\n",
              "                             decoded_target_from_ids  \n",
              "0                           im nearly out of propane  \n",
              "1                                  أتريدين كأسا آخر؟  \n",
              "2                                     mm youre funny  \n",
              "3      However, these beliefs are clearly justified.  \n",
              "4  read and participate on the rising voices blog...  "
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Micro-step 13: manual audit of random final tokenized examples\n",
        "sample_n = min(5, len(train_tok))\n",
        "audit_ds = train_tok.shuffle().select(range(sample_n))\n",
        "\n",
        "audit_rows = []\n",
        "for item in audit_ds:\n",
        "    src_ids = item[\"input_ids\"]\n",
        "    lbl_ids = item[\"labels\"]\n",
        "    audit_rows.append({\n",
        "        \"direction\": item.get(\"direction\", \"\"),\n",
        "        \"source_text\": item[\"source_text\"],\n",
        "        \"target_text\": item[\"target_text\"],\n",
        "        \"source_len\": len(src_ids),\n",
        "        \"target_len\": len(lbl_ids),\n",
        "        \"source_ids\": src_ids,\n",
        "        \"target_ids\": lbl_ids,\n",
        "        \"decoded_source_from_ids\": hf_tokenizer.decode(src_ids, skip_special_tokens=False),\n",
        "        \"decoded_target_from_ids\": hf_tokenizer.decode(lbl_ids, skip_special_tokens=False),\n",
        "    })\n",
        "\n",
        "tokenized_audit_df = pd.DataFrame(audit_rows)\n",
        "tokenized_audit_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "986a8afd",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "Direction : ar_to_en\n",
            "Source    : <2en> فقد نفذ مني البروبان تقريبا\n",
            "Target    : im nearly out of propane\n",
            "Input IDs : [5, 3071, 18650, 4714, 1520, 16742, 4348]\n",
            "Labels    : [431, 9763, 684, 333, 4298, 2385]\n",
            "Attn Mask : [1, 1, 1, 1, 1, 1, 1]\n",
            "Decoded S : <2en> فقد نفذ مني البروبان تقريبا\n",
            "Decoded T : im nearly out of propane\n",
            "============================================================\n",
            "Direction : en_to_ar\n",
            "Source    : <2ar> another glass for the lady\n",
            "Target    : أتريدين كأسا آخر؟\n",
            "Input IDs : [4, 2200, 1849, 434, 295, 5523]\n",
            "Labels    : [27912, 17415, 1714, 411]\n",
            "Attn Mask : [1, 1, 1, 1, 1, 1]\n",
            "Decoded S : <2ar> another glass for the lady\n",
            "Decoded T : أتريدين كأسا آخر؟\n",
            "============================================================\n",
            "Direction : ar_to_en\n",
            "Source    : <2en> أنت مضحك\n",
            "Target    : mm youre funny\n",
            "Input IDs : [5, 895, 10872]\n",
            "Labels    : [3683, 1151, 5910]\n",
            "Attn Mask : [1, 1, 1]\n",
            "Decoded S : <2en> أنت مضحك\n",
            "Decoded T : mm youre funny\n",
            "============================================================\n",
            "Direction : ar_to_en\n",
            "Source    : <2en> رغم ذلك، فإن هذه المعتقدات لها ما يبررها بوضوح.\n",
            "Target    : However, these beliefs are clearly justified.\n",
            "Input IDs : [5, 10193, 569, 360, 3970, 687, 332, 1144, 335, 1949, 546, 324, 516, 269, 383, 15302, 19]\n",
            "Labels    : [3799, 17, 1614, 18768, 88, 450, 13120, 798, 4290, 19]\n",
            "Attn Mask : [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "Decoded S : <2en> رغم ذلك، فإن هذه المعتقدات لها ما يبررها بوضوح.\n",
            "Decoded T : However, these beliefs are clearly justified.\n",
            "============================================================\n",
            "Direction : ar_to_en\n",
            "Source    : <2en> قراءة والمشاركة في مدونة الاصوات الصاعدة لمتابعة اخبار الحايزين على المنح ودراسات عن المشاريع القايمة واخبار عن مجموعات العمل يرجة ترك تعليق في حالة وجود شيء حاز الاهتمام\n",
            "Target    : read and participate on the rising voices blog for news about grantees case studies of projects and news from our working groups please leave a comment if there is something you find interesting.\n",
            "Input IDs : [5, 10144, 1723, 12101, 325, 7438, 2178, 29307, 14231, 4010, 15854, 465, 1275, 4937, 378, 6814, 312, 7220, 2536, 543, 12734, 532, 1275, 596, 17588, 1321, 543, 8283, 1484, 15945, 274, 2727, 15503, 325, 4306, 3848, 1165, 29917, 14272]\n",
            "Labels    : [4776, 355, 18161, 372, 295, 13727, 2129, 2799, 434, 3653, 849, 11423, 7041, 3035, 11132, 333, 8794, 355, 3653, 639, 1350, 2579, 6796, 2091, 2877, 275, 9586, 1415, 903, 368, 1550, 353, 1791, 9482, 19]\n",
            "Attn Mask : [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "Decoded S : <2en> قراءة والمشاركة في مدونة الاصوات الصاعدة لمتابعة اخبار الحايزين على المنح ودراسات عن المشاريع القايمة واخبار عن مجموعات العمل يرجة ترك تعليق في حالة وجود شيء حاز الاهتمام\n",
            "Decoded T : read and participate on the rising voices blog for news about grantees case studies of projects and news from our working groups please leave a comment if there is something you find interesting.\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "for item in audit_ds:\n",
        "    print(\"=\" * 60)\n",
        "    print(f\"Direction : {item.get('direction', '')}\")\n",
        "    print(f\"Source    : {item['source_text']}\")\n",
        "    print(f\"Target    : {item['target_text']}\")\n",
        "    print(f\"Input IDs : {item['input_ids']}\")\n",
        "    print(f\"Labels    : {item['labels']}\")\n",
        "    print(f\"Attn Mask : {item['attention_mask']}\")\n",
        "    print(f\"Decoded S : {hf_tokenizer.decode(item['input_ids'], skip_special_tokens=False)}\")\n",
        "    print(f\"Decoded T : {hf_tokenizer.decode(item['labels'], skip_special_tokens=False)}\")\n",
        "print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "a2f9979c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initialized random BART model (no pretrained weights).\n",
            "Vocab size: 32,000\n",
            "d_model: 512, enc_layers: 6, dec_layers: 6\n",
            "Total params: 60,659,712\n",
            "Trainable params: 60,659,712\n"
          ]
        }
      ],
      "source": [
        "# Micro-step 14: define and instantiate random-init BART model\n",
        "from transformers import BartConfig, BartForConditionalGeneration\n",
        "\n",
        "bart_config = BartConfig(\n",
        "    vocab_size=hf_tokenizer.vocab_size,\n",
        "    max_position_embeddings=config.max_seq_len + 2,\n",
        "    d_model=512,\n",
        "    encoder_layers=6,\n",
        "    decoder_layers=6,\n",
        "    encoder_attention_heads=8,\n",
        "    decoder_attention_heads=8,\n",
        "    encoder_ffn_dim=2048,\n",
        "    decoder_ffn_dim=2048,\n",
        "    dropout=0.1, # Main residual dropout (applied after attention & FFN blocks)\n",
        "    attention_dropout=0.1, # Dropout applied to attention probabilities\n",
        "    activation_dropout=0.0, # Dropout after FFN activation (kept 0 for stability)\n",
        "    pad_token_id=hf_tokenizer.pad_token_id,\n",
        "    bos_token_id=hf_tokenizer.bos_token_id,\n",
        "    eos_token_id=hf_tokenizer.eos_token_id,\n",
        "    decoder_start_token_id=hf_tokenizer.bos_token_id, # the decoder will start with <bos> to predict the first token\n",
        ")\n",
        "\n",
        "model = BartForConditionalGeneration(bart_config)\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(\"Initialized random BART model (no pretrained weights).\")\n",
        "print(f\"Vocab size: {bart_config.vocab_size:,}\")\n",
        "print(f\"d_model: {bart_config.d_model}, enc_layers: {bart_config.encoder_layers}, dec_layers: {bart_config.decoder_layers}\")\n",
        "print(f\"Total params: {total_params:,}\")\n",
        "print(f\"Trainable params: {trainable_params:,}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "3e17c187",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: cuda\n",
            "Probe batch size: 8\n",
            "Loss: 10.462287\n",
            "Logits shape: (8, 17, 32000)\n",
            "tensor([[[ 0.0000e+00,  4.7105e+00,  7.3093e-01,  ..., -1.7524e-01,\n",
            "          -4.8019e-01, -2.6668e-01],\n",
            "         [ 0.0000e+00,  8.7805e-04, -7.4898e-01,  ...,  1.4209e-01,\n",
            "           7.2610e-02, -9.1130e-02],\n",
            "         [ 0.0000e+00, -1.0881e-01,  3.3885e-01,  ..., -6.3099e-01,\n",
            "          -1.9324e-01, -2.8855e-01],\n",
            "         ...,\n",
            "         [ 0.0000e+00, -1.6474e-01,  3.3509e-01,  ..., -8.8127e-02,\n",
            "          -6.1816e-01, -4.6103e-01],\n",
            "         [ 0.0000e+00,  1.9915e-01,  2.0464e-01,  ...,  2.3678e-01,\n",
            "           2.9234e-01, -7.0112e-01],\n",
            "         [ 0.0000e+00, -7.7394e-01, -3.0749e-01,  ..., -1.1064e-01,\n",
            "          -6.7551e-01, -4.5202e-01]],\n",
            "\n",
            "        [[ 0.0000e+00,  4.4847e+00,  1.6182e-01,  ...,  7.3620e-01,\n",
            "          -7.9925e-01,  6.1794e-02],\n",
            "         [ 0.0000e+00,  1.7318e-01, -5.4782e-01,  ...,  8.3050e-01,\n",
            "           3.1044e-01, -4.5127e-02],\n",
            "         [ 0.0000e+00,  3.1265e-01,  2.2879e-01,  ...,  3.6026e-01,\n",
            "          -1.7683e-01,  1.7019e-01],\n",
            "         ...,\n",
            "         [ 0.0000e+00, -4.4010e-01,  3.3349e-01,  ..., -8.5355e-02,\n",
            "          -7.3155e-01, -6.4830e-01],\n",
            "         [ 0.0000e+00,  6.2435e-02,  1.1837e-01,  ...,  9.6366e-01,\n",
            "          -3.9614e-02, -5.8873e-01],\n",
            "         [ 0.0000e+00, -6.7187e-01, -4.7464e-01,  ...,  4.9651e-01,\n",
            "          -8.4196e-01, -7.7626e-02]],\n",
            "\n",
            "        [[ 0.0000e+00,  4.8843e+00,  2.0838e-01,  ...,  2.2584e-01,\n",
            "          -3.7806e-01, -2.3811e-01],\n",
            "         [ 0.0000e+00,  9.2063e-01,  2.2336e-01,  ...,  1.8629e-01,\n",
            "           8.8773e-02,  5.5645e-03],\n",
            "         [ 0.0000e+00,  2.7102e-02,  5.2305e-01,  ..., -3.4762e-01,\n",
            "          -2.6219e-02,  1.2230e-01],\n",
            "         ...,\n",
            "         [ 0.0000e+00, -1.1504e-01,  2.4596e-01,  ...,  5.7914e-02,\n",
            "          -6.5451e-01, -5.2203e-01],\n",
            "         [ 0.0000e+00,  7.5917e-01,  2.2537e-01,  ...,  2.7616e-01,\n",
            "           2.4535e-01, -6.2797e-01],\n",
            "         [ 0.0000e+00, -5.1467e-01, -3.8168e-01,  ...,  2.2677e-01,\n",
            "          -7.1851e-01, -3.7719e-01]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 0.0000e+00,  4.7134e+00,  5.6617e-01,  ...,  2.2364e-01,\n",
            "          -4.5150e-01, -7.3673e-02],\n",
            "         [ 0.0000e+00, -1.6841e-01, -6.0212e-01,  ...,  5.8750e-01,\n",
            "          -7.5917e-01, -2.7252e-01],\n",
            "         [ 0.0000e+00,  6.4972e-02,  1.6391e-01,  ..., -3.6285e-01,\n",
            "          -2.0282e-01, -2.0664e-01],\n",
            "         ...,\n",
            "         [ 0.0000e+00, -2.3461e-01,  6.3549e-01,  ..., -3.0435e-01,\n",
            "          -7.3439e-01, -2.9811e-01],\n",
            "         [ 0.0000e+00,  5.0897e-01,  3.7496e-01,  ...,  1.3678e-02,\n",
            "           4.2935e-01, -8.0202e-01],\n",
            "         [ 0.0000e+00, -3.9714e-01, -2.0764e-01,  ...,  2.9859e-01,\n",
            "          -1.0282e+00, -3.4558e-01]],\n",
            "\n",
            "        [[ 0.0000e+00,  4.5708e+00,  5.2437e-01,  ...,  5.1877e-01,\n",
            "          -2.9951e-01, -1.2510e-02],\n",
            "         [ 0.0000e+00,  4.0698e-01, -2.7595e-01,  ...,  1.1461e+00,\n",
            "          -3.3476e-02,  2.6396e-01],\n",
            "         [ 0.0000e+00,  3.8511e-01,  4.8728e-01,  ...,  3.9550e-01,\n",
            "          -1.3272e-01,  4.3644e-01],\n",
            "         ...,\n",
            "         [ 0.0000e+00, -3.2063e-01,  4.0171e-01,  ..., -3.3170e-01,\n",
            "          -1.0531e+00, -7.2565e-01],\n",
            "         [ 0.0000e+00,  3.4164e-01,  1.7781e-01,  ...,  5.8501e-01,\n",
            "           4.4499e-01, -2.2578e-01],\n",
            "         [ 0.0000e+00, -3.4405e-01, -4.3470e-01,  ...,  1.6675e-01,\n",
            "          -1.1106e+00, -2.6546e-02]],\n",
            "\n",
            "        [[ 0.0000e+00,  4.4977e+00,  2.9502e-02,  ...,  3.4828e-01,\n",
            "          -5.3841e-01, -2.8886e-01],\n",
            "         [ 0.0000e+00,  2.0281e-01, -1.5963e-01,  ...,  6.0572e-01,\n",
            "          -5.1705e-01,  9.3550e-01],\n",
            "         [ 0.0000e+00,  5.5271e-01,  3.3655e-01,  ...,  2.8731e-01,\n",
            "          -7.7673e-02,  3.5543e-01],\n",
            "         ...,\n",
            "         [ 0.0000e+00, -4.7293e-01, -2.0923e-01,  ..., -4.6760e-01,\n",
            "          -9.5080e-01, -8.1991e-03],\n",
            "         [ 0.0000e+00,  5.3015e-01,  1.9770e-01,  ...,  6.9023e-01,\n",
            "           7.4364e-02, -4.7247e-01],\n",
            "         [ 0.0000e+00, -9.2879e-01, -5.4029e-01,  ...,  6.0400e-01,\n",
            "          -4.2455e-01, -2.9122e-01]]], device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        }
      ],
      "source": [
        "# Micro-step 15: one-batch forward-pass sanity check\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "model.train()\n",
        "\n",
        "probe_size = min(8, len(train_tok_model))\n",
        "probe_ds = train_tok_model.shuffle(seed=RANDOM_SEED).select(range(probe_size))\n",
        "probe_features = [probe_ds[i] for i in range(len(probe_ds))]\n",
        "probe_batch = data_collator(probe_features)\n",
        "\n",
        "batch_on_device = {k: v.to(device) for k, v in probe_batch.items()}\n",
        "outputs = model(**batch_on_device)\n",
        "\n",
        "loss_value = float(outputs.loss.detach().cpu().item())\n",
        "assert np.isfinite(loss_value), f\"Non-finite loss detected: {loss_value}\"\n",
        "\n",
        "print(f\"Device: {device}\")\n",
        "print(f\"Probe batch size: {probe_size}\")\n",
        "print(f\"Loss: {loss_value:.6f}\")\n",
        "print(f\"Logits shape: {tuple(outputs.logits.shape)}\")\n",
        "print(outputs.logits)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "b0393e92",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "max learning_rate: 0.0003\n",
            "min_lr_rate ratio: 0.10\n",
            "min_lr value: 2.9999999999999997e-05\n",
            "weight_decay: 0.01\n",
            "adam_betas: (0.9, 0.98)\n",
            "max_steps: 32,000\n",
            "num_warmup_steps: 480\n"
          ]
        }
      ],
      "source": [
        "# Micro-step 16: training hyperparameters + optimizer/scheduler setup\n",
        "from transformers import get_cosine_with_min_lr_schedule_with_warmup\n",
        "\n",
        "assert \"model\" in globals(), \"Model must be initialized before optimizer setup\"\n",
        "\n",
        "learning_rate = 3e-4\n",
        "weight_decay = 0.01\n",
        "adam_betas = (0.9, 0.98)\n",
        "adam_eps = 1e-8\n",
        "\n",
        "max_steps = 32_000\n",
        "warmup_ratio = 0.015\n",
        "num_warmup_steps = int(max_steps * warmup_ratio)\n",
        "\n",
        "# Cosine decay floor: keep LR at >=10% of initial LR\n",
        "min_lr_rate = 0.10\n",
        "min_lr = learning_rate * min_lr_rate\n",
        "\n",
        "optimizer = torch.optim.AdamW(\n",
        "    model.parameters(),\n",
        "    lr=learning_rate,\n",
        "    betas=adam_betas,\n",
        "    eps=adam_eps,\n",
        "    weight_decay=weight_decay,\n",
        ")\n",
        "\n",
        "lr_scheduler = get_cosine_with_min_lr_schedule_with_warmup(\n",
        "    optimizer=optimizer,\n",
        "    num_warmup_steps=num_warmup_steps,\n",
        "    num_training_steps=max_steps,\n",
        "    min_lr_rate=min_lr_rate,\n",
        ")\n",
        "\n",
        "print(f\"max learning_rate: {learning_rate}\")\n",
        "print(f\"min_lr_rate ratio: {min_lr_rate:.2f}\")\n",
        "print(f\"min_lr value: {min_lr}\")\n",
        "print(f\"weight_decay: {weight_decay}\")\n",
        "print(f\"adam_betas: {adam_betas}\")\n",
        "print(f\"max_steps: {max_steps:,}\")\n",
        "print(f\"num_warmup_steps: {num_warmup_steps:,}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "05f8e977",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enabling TF32 for matmul and cuDNN (Ampere+ GPUs)\n",
            "use_gradient_checkpointing: False\n",
            "use_fp16: True\n",
            "per_device_train_batch_size: 14\n",
            "gradient_accumulation_steps: 8\n",
            "effective_batch_size (examples/update): 112\n"
          ]
        }
      ],
      "source": [
        "# Micro-step 17: runtime memory config (checkpointing OFF by default)\n",
        "assert \"model\" in globals(), \"Model must exist before runtime memory config\"\n",
        "\n",
        "# Start simple: no gradient checkpointing unless we face OOM\n",
        "use_gradient_checkpointing = False\n",
        "if use_gradient_checkpointing:\n",
        "    model.gradient_checkpointing_enable()\n",
        "else:\n",
        "    model.gradient_checkpointing_disable()\n",
        "\n",
        "# Mixed precision for 8GB VRAM training efficiency\n",
        "use_fp16 = torch.cuda.is_available()\n",
        "try:\n",
        "    grad_scaler = torch.amp.GradScaler(\"cuda\", enabled=use_fp16)\n",
        "except TypeError:\n",
        "    # Fallback for older torch versions\n",
        "    grad_scaler = torch.cuda.amp.GradScaler(enabled=use_fp16)\n",
        "\n",
        "# Initial batch settings (can be tuned after smoke run)\n",
        "per_device_train_batch_size = 14\n",
        "gradient_accumulation_steps = 8\n",
        "effective_batch_size = per_device_train_batch_size * gradient_accumulation_steps\n",
        "\n",
        "# Optional acceleration on Ampere+ GPUs\n",
        "if torch.cuda.is_available() and hasattr(torch.backends.cuda.matmul, \"allow_tf32\"):\n",
        "    print(\"Enabling TF32 for matmul and cuDNN (Ampere+ GPUs)\")\n",
        "    torch.backends.cuda.matmul.allow_tf32 = True\n",
        "    torch.backends.cudnn.allow_tf32 = True\n",
        "\n",
        "print(f\"use_gradient_checkpointing: {use_gradient_checkpointing}\")\n",
        "print(f\"use_fp16: {use_fp16}\")\n",
        "print(f\"per_device_train_batch_size: {per_device_train_batch_size}\")\n",
        "print(f\"gradient_accumulation_steps: {gradient_accumulation_steps}\")\n",
        "print(f\"effective_batch_size (examples/update): {effective_batch_size}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "371820c6",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training-volume summary:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style type=\"text/css\">\n",
              "</style>\n",
              "<table id=\"T_32342\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_32342_level0_col0\" class=\"col_heading level0 col0\" >metric</th>\n",
              "      <th id=\"T_32342_level0_col1\" class=\"col_heading level0 col1\" >value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_32342_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
              "      <td id=\"T_32342_row0_col0\" class=\"data row0 col0\" >examples_per_micro_batch</td>\n",
              "      <td id=\"T_32342_row0_col1\" class=\"data row0 col1\" >14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_32342_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
              "      <td id=\"T_32342_row1_col0\" class=\"data row1 col0\" >gradient_accumulation_steps</td>\n",
              "      <td id=\"T_32342_row1_col1\" class=\"data row1 col1\" >8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_32342_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
              "      <td id=\"T_32342_row2_col0\" class=\"data row2 col0\" >examples_per_optimizer_step</td>\n",
              "      <td id=\"T_32342_row2_col1\" class=\"data row2 col1\" >112</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_32342_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
              "      <td id=\"T_32342_row3_col0\" class=\"data row3 col0\" >max_steps</td>\n",
              "      <td id=\"T_32342_row3_col1\" class=\"data row3 col1\" >32,000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_32342_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
              "      <td id=\"T_32342_row4_col0\" class=\"data row4 col0\" >examples_seen_total</td>\n",
              "      <td id=\"T_32342_row4_col1\" class=\"data row4 col1\" >3,584,000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_32342_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
              "      <td id=\"T_32342_row5_col0\" class=\"data row5 col0\" >train_examples</td>\n",
              "      <td id=\"T_32342_row5_col1\" class=\"data row5 col1\" >1,489,852</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_32342_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
              "      <td id=\"T_32342_row6_col0\" class=\"data row6 col0\" >approx_epochs_over_train_split</td>\n",
              "      <td id=\"T_32342_row6_col1\" class=\"data row6 col1\" >2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_32342_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
              "      <td id=\"T_32342_row7_col0\" class=\"data row7 col0\" >coverage_percent_of_train_split %</td>\n",
              "      <td id=\"T_32342_row7_col1\" class=\"data row7 col1\" >241</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ],
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x25a65469ca0>"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Micro-step 18: dynamic training-volume analytics\n",
        "assert \"per_device_train_batch_size\" in globals(), \"Run runtime config cell first\"\n",
        "assert \"gradient_accumulation_steps\" in globals(), \"Run runtime config cell first\"\n",
        "assert \"max_steps\" in globals(), \"Run optimizer/scheduler cell first\"\n",
        "assert \"train_df\" in globals(), \"Run split/bidirectional cells first\"\n",
        "\n",
        "examples_per_micro_batch = int(per_device_train_batch_size)\n",
        "examples_per_optimizer_step = int(per_device_train_batch_size * gradient_accumulation_steps)\n",
        "examples_seen_total = int(max_steps * examples_per_optimizer_step)\n",
        "train_examples = int(len(train_df))\n",
        "approx_epochs = (examples_seen_total / train_examples) if train_examples else 0.0\n",
        "\n",
        "analytics_df = pd.DataFrame([\n",
        "    {\"metric\": \"examples_per_micro_batch\", \"value\": examples_per_micro_batch},\n",
        "    {\"metric\": \"gradient_accumulation_steps\", \"value\": int(gradient_accumulation_steps)},\n",
        "    {\"metric\": \"examples_per_optimizer_step\", \"value\": examples_per_optimizer_step},\n",
        "    {\"metric\": \"max_steps\", \"value\": int(max_steps)},\n",
        "    {\"metric\": \"examples_seen_total\", \"value\": examples_seen_total},\n",
        "    {\"metric\": \"train_examples\", \"value\": train_examples},\n",
        "    {\"metric\": \"approx_epochs_over_train_split\", \"value\": round(approx_epochs, 4)},\n",
        "    {\"metric\": \"coverage_percent_of_train_split %\", \"value\": round(approx_epochs * 100, 2)},\n",
        "])\n",
        "\n",
        "analytics_df = analytics_df.astype({\"value\": float})\n",
        "\n",
        "\n",
        "print(\"Training-volume summary:\")\n",
        "analytics_df.style.format({\"value\": \"{:,.0f}\"})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "b488c21d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "max_steps: 32,000\n",
            "sec_per_step_estimate: 1.500\n",
            "estimated_total_seconds: 48,000\n",
            "estimated_total_hours: 13.33\n",
            "if 1.0s/step -> 8.89 hours\n",
            "if 1.5s/step -> 13.33 hours\n",
            "if 2.0s/step -> 17.78 hours\n",
            "if 2.5s/step -> 22.22 hours\n",
            "if 3.0s/step -> 26.67 hours\n"
          ]
        }
      ],
      "source": [
        "# Micro-step 19: quick training-time estimate for current max_steps\n",
        "assert \"max_steps\" in globals(), \"Run optimizer/scheduler setup cell first\"\n",
        "\n",
        "# Set this after a short timed run (seconds per optimizer step)\n",
        "sec_per_step_estimate = 1.5\n",
        "\n",
        "total_seconds = max_steps * sec_per_step_estimate\n",
        "total_hours = total_seconds / 3600\n",
        "\n",
        "print(f\"max_steps: {max_steps:,}\")\n",
        "print(f\"sec_per_step_estimate: {sec_per_step_estimate:.3f}\")\n",
        "print(f\"estimated_total_seconds: {total_seconds:,.0f}\")\n",
        "print(f\"estimated_total_hours: {total_hours:.2f}\")\n",
        "\n",
        "for s in [1.0, 1.5, 2.0, 2.5, 3.0]:\n",
        "    h = (max_steps * s) / 3600\n",
        "    print(f\"if {s:.1f}s/step -> {h:.2f} hours\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "022dd3e0",
      "metadata": {},
      "outputs": [],
      "source": [
        "# model = BartForConditionalGeneration(bart_config)\n",
        "# model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "268a968a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.compile: skipped (CUDA or torch.compile unavailable)\n"
          ]
        }
      ],
      "source": [
        "# Micro-step 19b: optional torch.compile acceleration\n",
        "use_torch_compile = False #torch.cuda.is_available() and hasattr(torch, \"compile\")\n",
        "\n",
        "if use_torch_compile:\n",
        "    try:\n",
        "        # `reduce-overhead` is a practical starting mode for training loops\n",
        "        model = torch.compile(model, backend=\"eager\", dynamic=True)\n",
        "        print(\"torch.compile: enabled\")\n",
        "    except Exception as e:\n",
        "        print(f\"torch.compile: failed, continuing without compile. reason={e}\")\n",
        "else:\n",
        "    print(\"torch.compile: skipped (CUDA or torch.compile unavailable)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "9ff79e6f",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "step=  1 avg_train_loss=10.4594 lr=6.25e-07\n",
            "step= 10 avg_train_loss=10.4527 lr=6.25e-06\n",
            "step= 20 avg_train_loss=10.4176 lr=1.25e-05\n",
            "step= 30 avg_train_loss=10.3541 lr=1.875e-05\n",
            "step= 40 avg_train_loss=10.2686 lr=2.5e-05\n",
            "step= 50 avg_train_loss=10.1809 lr=3.125e-05\n",
            "------------------------------------------------------------\n",
            "smoke optimizer steps completed: 50\n",
            "elapsed_sec: 104.25\n",
            "steps_per_sec: 0.4796\n",
            "sec_per_step_estimate: 2.0850\n",
            "val_loss_single_batch: 9.5379\n",
            "peak_cuda_memory_gb: 2.543\n"
          ]
        }
      ],
      "source": [
        "# Micro-step 20: 50-step smoke training run\n",
        "import time\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "smoke_steps = 50\n",
        "assert smoke_steps > 0, \"smoke_steps must be positive\"\n",
        "\n",
        "train_tok_model = train_tok.remove_columns([c for c in train_tok.column_names if c not in [\"input_ids\", \"attention_mask\", \"labels\"]])\n",
        "val_tok_model = val_tok.remove_columns([c for c in val_tok.column_names if c not in [\"input_ids\", \"attention_mask\", \"labels\"]])\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_tok_model,\n",
        "    batch_size=per_device_train_batch_size,\n",
        "    shuffle=True,\n",
        "    collate_fn=data_collator,\n",
        "    drop_last=False,\n",
        "    num_workers=2,\n",
        "    pin_memory=True,\n",
        ")\n",
        "val_loader = DataLoader(\n",
        "    val_tok_model,\n",
        "    batch_size=per_device_train_batch_size,\n",
        "    shuffle=False,\n",
        "    collate_fn=data_collator,\n",
        "    drop_last=False,\n",
        "    num_workers=2,\n",
        "    pin_memory=True,\n",
        ")\n",
        "\n",
        "model.train()\n",
        "optimizer.zero_grad(set_to_none=True)\n",
        "start = time.time()\n",
        "running_loss = 0.0\n",
        "optimizer_steps_done = 0\n",
        "\n",
        "for micro_step, batch in enumerate(train_loader, start=1):\n",
        "    if optimizer_steps_done >= smoke_steps:\n",
        "        break\n",
        "\n",
        "    batch = {k: v.to(device) for k, v in batch.items()}\n",
        "\n",
        "    if use_fp16:\n",
        "        with torch.amp.autocast(device_type=\"cuda\", dtype=torch.float16):\n",
        "            out = model(**batch)\n",
        "            loss = out.loss / gradient_accumulation_steps\n",
        "        grad_scaler.scale(loss).backward()\n",
        "    else:\n",
        "        out = model(**batch)\n",
        "        loss = out.loss / gradient_accumulation_steps\n",
        "        loss.backward()\n",
        "\n",
        "    running_loss += float(out.loss.detach().cpu().item())\n",
        "\n",
        "    if micro_step % gradient_accumulation_steps == 0:\n",
        "        if use_fp16:\n",
        "            grad_scaler.step(optimizer)\n",
        "            grad_scaler.update()\n",
        "        else:\n",
        "            optimizer.step()\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        lr_scheduler.step()\n",
        "        optimizer_steps_done += 1\n",
        "\n",
        "        if optimizer_steps_done % 10 == 0 or optimizer_steps_done == 1:\n",
        "            avg_loss = running_loss / micro_step\n",
        "            current_lr = optimizer.param_groups[0][\"lr\"]\n",
        "            print(f\"step={optimizer_steps_done:>3} avg_train_loss={avg_loss:.4f} lr={current_lr:.6g}\")\n",
        "\n",
        "# Quick single-batch validation check\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    val_batch = next(iter(val_loader))\n",
        "    val_batch = {k: v.to(device) for k, v in val_batch.items()}\n",
        "    if use_fp16:\n",
        "        with torch.amp.autocast(device_type=\"cuda\", dtype=torch.float16):\n",
        "            val_out = model(**val_batch)\n",
        "    else:\n",
        "        val_out = model(**val_batch)\n",
        "\n",
        "elapsed = time.time() - start\n",
        "steps_per_sec = optimizer_steps_done / elapsed if elapsed > 0 else 0.0\n",
        "sec_per_step_estimate = 1.0 / steps_per_sec if steps_per_sec > 0 else float(\"inf\")\n",
        "\n",
        "print(\"-\" * 60)\n",
        "print(f\"smoke optimizer steps completed: {optimizer_steps_done}\")\n",
        "print(f\"elapsed_sec: {elapsed:.2f}\")\n",
        "print(f\"steps_per_sec: {steps_per_sec:.4f}\")\n",
        "print(f\"sec_per_step_estimate: {sec_per_step_estimate:.4f}\")\n",
        "print(f\"val_loss_single_batch: {float(val_out.loss.detach().cpu().item()):.4f}\")\n",
        "if torch.cuda.is_available():\n",
        "    peak_mem_gb = torch.cuda.max_memory_allocated(device) / (1024**3)\n",
        "    print(f\"peak_cuda_memory_gb: {peak_mem_gb:.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7db6cb69",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Micro-step 21a: helper functions for eval, metrics, and checkpointing\n",
        "import math\n",
        "\n",
        "def _load_text_metrics(enable_comet=False):\n",
        "    try:\n",
        "        import evaluate\n",
        "    except ImportError as e:\n",
        "        raise ImportError(\"`evaluate` is required for BLEU/chrF metrics. Install: pip install evaluate sacrebleu\") from e\n",
        "\n",
        "    _bleu_metric = evaluate.load(\"sacrebleu\")\n",
        "    _chrf_metric = evaluate.load(\"chrf\")\n",
        "    _comet_metric = None\n",
        "    if enable_comet:\n",
        "        try:\n",
        "            _comet_metric = evaluate.load(\"comet\")\n",
        "        except Exception as e:\n",
        "            print(f\"[warn] COMET unavailable; continuing without COMET. Reason: {e}\")\n",
        "            _comet_metric = None\n",
        "    return _bleu_metric, _chrf_metric, _comet_metric\n",
        "\n",
        "def _eval_val_loss(_model, _val_loader, _device, _use_fp16, _max_batches=None):\n",
        "    _model.eval()\n",
        "    losses = []\n",
        "    with torch.no_grad():\n",
        "        for b_idx, batch in enumerate(_val_loader):\n",
        "            if _max_batches is not None and b_idx >= _max_batches:\n",
        "                break\n",
        "            batch = {k: v.to(_device) for k, v in batch.items()}\n",
        "            if _use_fp16:\n",
        "                with torch.amp.autocast(device_type=\"cuda\", dtype=torch.float16):\n",
        "                    out = _model(**batch)\n",
        "            else:\n",
        "                out = _model(**batch)\n",
        "            losses.append(float(out.loss.detach().cpu().item()))\n",
        "    _model.train()\n",
        "    return float(np.mean(losses)) if losses else float(\"nan\")\n",
        "\n",
        "def _eval_text_metrics(\n",
        "    _model,\n",
        "    _tokenizer,\n",
        "    _eval_df,\n",
        "    _device,\n",
        "    _batch_size,\n",
        "    _max_batches,\n",
        "    _num_beams,\n",
        "    _seed,\n",
        "    _bleu_metric,\n",
        "    _chrf_metric,\n",
        "    _comet_metric=None,\n",
        "):\n",
        "\n",
        "    _model.eval()\n",
        "    if _eval_df is None or len(_eval_df) == 0:\n",
        "        _model.train()\n",
        "        return {\n",
        "            \"num_samples\": 0,\n",
        "            \"num_batches\": 0,\n",
        "            \"bleu\": float(\"nan\"),\n",
        "            \"chrf\": float(\"nan\"),\n",
        "            \"comet\": float(\"nan\"),\n",
        "            \"bleu_en_to_ar\": float(\"nan\"),\n",
        "            \"bleu_ar_to_en\": float(\"nan\"),\n",
        "            \"chrf_en_to_ar\": float(\"nan\"),\n",
        "            \"chrf_ar_to_en\": float(\"nan\"),\n",
        "        }\n",
        "\n",
        "    if _max_batches is None:\n",
        "        sample_df = _eval_df.reset_index(drop=True)\n",
        "    else:\n",
        "        max_samples = int(_max_batches * _batch_size)\n",
        "        max_samples = min(max_samples, len(_eval_df))\n",
        "        if max_samples <= 0:\n",
        "            _model.train()\n",
        "            return {\n",
        "                \"num_samples\": 0,\n",
        "                \"num_batches\": 0,\n",
        "                \"bleu\": float(\"nan\"),\n",
        "                \"chrf\": float(\"nan\"),\n",
        "                \"comet\": float(\"nan\"),\n",
        "                \"bleu_en_to_ar\": float(\"nan\"),\n",
        "                \"bleu_ar_to_en\": float(\"nan\"),\n",
        "                \"chrf_en_to_ar\": float(\"nan\"),\n",
        "                \"chrf_ar_to_en\": float(\"nan\"),\n",
        "            }\n",
        "        sample_df = _eval_df.sample(n=max_samples, random_state=int(_seed)).reset_index(drop=True)\n",
        "\n",
        "    preds = []\n",
        "    refs = []\n",
        "    srcs = []\n",
        "    dirs = []\n",
        "    with torch.no_grad():\n",
        "        for start in range(0, len(sample_df), _batch_size):\n",
        "            chunk = sample_df.iloc[start : start + _batch_size]\n",
        "            src_batch = chunk[\"source_text\"].astype(str).tolist()\n",
        "            ref_batch = chunk[\"target_text\"].astype(str).tolist()\n",
        "            dir_batch = chunk[\"direction\"].astype(str).tolist()\n",
        "\n",
        "            enc = _tokenizer(\n",
        "                src_batch,\n",
        "                truncation=True,\n",
        "                max_length=config.max_seq_len,\n",
        "                padding=True,\n",
        "                return_tensors=\"pt\",\n",
        "            )\n",
        "            enc = {k: v.to(_device) for k, v in enc.items()}\n",
        "            gen_ids = _model.generate(\n",
        "                **enc,\n",
        "                max_new_tokens=config.max_seq_len,\n",
        "                num_beams=_num_beams,\n",
        "                do_sample=False,\n",
        "            )\n",
        "            pred_batch = _tokenizer.batch_decode(gen_ids, skip_special_tokens=True)\n",
        "\n",
        "            preds.extend([p.strip() for p in pred_batch])\n",
        "            refs.extend([r.strip() for r in ref_batch])\n",
        "            srcs.extend(src_batch)\n",
        "            dirs.extend(dir_batch)\n",
        "\n",
        "    _model.train()\n",
        "\n",
        "    if len(preds) == 0:\n",
        "        return {\n",
        "            \"num_samples\": 0,\n",
        "            \"num_batches\": 0,\n",
        "            \"bleu\": float(\"nan\"),\n",
        "            \"chrf\": float(\"nan\"),\n",
        "            \"comet\": float(\"nan\"),\n",
        "            \"bleu_en_to_ar\": float(\"nan\"),\n",
        "            \"bleu_ar_to_en\": float(\"nan\"),\n",
        "            \"chrf_en_to_ar\": float(\"nan\"),\n",
        "            \"chrf_ar_to_en\": float(\"nan\"),\n",
        "        }\n",
        "\n",
        "    def _score_subset(_preds, _refs):\n",
        "        if len(_preds) == 0:\n",
        "            return float(\"nan\"), float(\"nan\")\n",
        "        _bleu = float(_bleu_metric.compute(predictions=_preds, references=[[r] for r in _refs])[\"score\"])\n",
        "        _chrf = float(_chrf_metric.compute(predictions=_preds, references=_refs)[\"score\"])\n",
        "        return _bleu, _chrf\n",
        "\n",
        "    bleu_all, chrf_all = _score_subset(preds, refs)\n",
        "    idx_en_to_ar = [i for i, d in enumerate(dirs) if d == \"en_to_ar\"]\n",
        "    idx_ar_to_en = [i for i, d in enumerate(dirs) if d == \"ar_to_en\"]\n",
        "    bleu_en_to_ar, chrf_en_to_ar = _score_subset([preds[i] for i in idx_en_to_ar], [refs[i] for i in idx_en_to_ar])\n",
        "    bleu_ar_to_en, chrf_ar_to_en = _score_subset([preds[i] for i in idx_ar_to_en], [refs[i] for i in idx_ar_to_en])\n",
        "\n",
        "    comet_score = float(\"nan\")\n",
        "    if _comet_metric is not None:\n",
        "        try:\n",
        "            comet_out = _comet_metric.compute(predictions=preds, references=refs, sources=srcs)\n",
        "            comet_score = float(comet_out.get(\"mean_score\", comet_out.get(\"score\", float(\"nan\"))))\n",
        "        except Exception as e:\n",
        "            print(f\"[warn] COMET scoring failed at runtime; continuing without COMET value. Reason: {e}\")\n",
        "\n",
        "    return {\n",
        "        \"num_samples\": int(len(preds)),\n",
        "        \"num_batches\": int(math.ceil(len(preds) / _batch_size)),\n",
        "        \"bleu\": bleu_all,\n",
        "        \"chrf\": chrf_all,\n",
        "        \"comet\": comet_score,\n",
        "        \"bleu_en_to_ar\": bleu_en_to_ar,\n",
        "        \"bleu_ar_to_en\": bleu_ar_to_en,\n",
        "        \"chrf_en_to_ar\": chrf_en_to_ar,\n",
        "        \"chrf_ar_to_en\": chrf_ar_to_en,\n",
        "    }\n",
        "\n",
        "def _save_checkpoint(_model, _tokenizer, _optimizer, _scheduler, _scaler, _step, _val_loss, _target_dir):\n",
        "    _target_dir.mkdir(parents=True, exist_ok=True)\n",
        "    _model.save_pretrained(str(_target_dir))\n",
        "    _tokenizer.save_pretrained(str(_target_dir / \"tokenizer\"))\n",
        "    torch.save({\n",
        "        \"step\": int(_step),\n",
        "        \"val_loss\": float(_val_loss) if _val_loss is not None else None,\n",
        "        \"optimizer\": _optimizer.state_dict(),\n",
        "        \"scheduler\": _scheduler.state_dict(),\n",
        "        \"scaler\": _scaler.state_dict() if _scaler is not None else None,\n",
        "    }, _target_dir / \"trainer_state.pt\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd5a226d",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Micro-step 21: full training loop with interval logging, checkpoints, and best-model tracking\n",
        "import json as pyjson\n",
        "import shutil\n",
        "import time\n",
        "from datetime import datetime\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# -----------------------------\n",
        "# Tunable run hyperparameters\n",
        "# -----------------------------\n",
        "log_every_steps = 50\n",
        "eval_every_steps = 200\n",
        "save_every_steps = 500\n",
        "keep_last_n_checkpoints = 3\n",
        "max_val_batches = 300  # set None to use full val loader\n",
        "text_metric_num_beams = 1\n",
        "max_text_metric_batches_log = 1   # lightweight text-metric pass at log intervals\n",
        "max_text_metric_batches_eval = 8  # stronger text-metric pass at eval intervals\n",
        "enable_comet = False\n",
        "train_num_workers = 2\n",
        "val_num_workers = 2\n",
        "pin_memory = True\n",
        "\n",
        "assert max_steps > 0, \"max_steps must be > 0\"\n",
        "assert gradient_accumulation_steps > 0, \"gradient_accumulation_steps must be > 0\"\n",
        "\n",
        "# Build train/val model-input datasets (dynamic padding via collator)\n",
        "model_input_cols = [\"input_ids\", \"attention_mask\", \"labels\"]\n",
        "train_tok_model = train_tok.remove_columns([c for c in train_tok.column_names if c not in model_input_cols])\n",
        "val_tok_model = val_tok.remove_columns([c for c in val_tok.column_names if c not in model_input_cols])\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_tok_model,\n",
        "    batch_size=per_device_train_batch_size,\n",
        "    shuffle=True,\n",
        "    collate_fn=data_collator,\n",
        "    num_workers=train_num_workers,\n",
        "    pin_memory=pin_memory,\n",
        "    persistent_workers=(train_num_workers > 0),\n",
        ")\n",
        "val_loader = DataLoader(\n",
        "    val_tok_model,\n",
        "    batch_size=per_device_train_batch_size,\n",
        "    shuffle=True,\n",
        "    collate_fn=data_collator,\n",
        "    num_workers=val_num_workers,\n",
        "    pin_memory=pin_memory,\n",
        "    persistent_workers=(val_num_workers > 0),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f3c46ba",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run dirs and paths\n",
        "run_id = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "run_dir = PROJECT_ROOT / \"artifacts\" / \"runs\" / run_id\n",
        "ckpt_root = PROJECT_ROOT / \"checkpoints\" / run_id\n",
        "best_dir = ckpt_root / \"best_model\"\n",
        "run_dir.mkdir(parents=True, exist_ok=True)\n",
        "ckpt_root.mkdir(parents=True, exist_ok=True)\n",
        "best_dir.mkdir(parents=True, exist_ok=True)\n",
        "train_metrics_path = run_dir / \"train_metrics.csv\"\n",
        "eval_metrics_path = run_dir / \"eval_metrics.csv\"\n",
        "config_path = run_dir / \"run_config.json\"\n",
        "\n",
        "run_config = {\n",
        "    \"run_id\": run_id,\n",
        "    \"learning_rate\": learning_rate,\n",
        "    \"min_lr_rate\": min_lr_rate,\n",
        "    \"weight_decay\": weight_decay,\n",
        "    \"adam_betas\": list(adam_betas),\n",
        "    \"adam_eps\": adam_eps,\n",
        "    \"max_steps\": max_steps,\n",
        "    \"warmup_ratio\": warmup_ratio,\n",
        "    \"num_warmup_steps\": num_warmup_steps,\n",
        "    \"per_device_train_batch_size\": per_device_train_batch_size,\n",
        "    \"gradient_accumulation_steps\": gradient_accumulation_steps,\n",
        "    \"effective_batch_size\": effective_batch_size,\n",
        "    \"use_fp16\": bool(use_fp16),\n",
        "    \"use_gradient_checkpointing\": bool(use_gradient_checkpointing),\n",
        "    \"log_every_steps\": log_every_steps,\n",
        "    \"eval_every_steps\": eval_every_steps,\n",
        "    \"save_every_steps\": save_every_steps,\n",
        "    \"keep_last_n_checkpoints\": keep_last_n_checkpoints,\n",
        "    \"max_val_batches\": max_val_batches,\n",
        "    \"text_metric_num_beams\": text_metric_num_beams,\n",
        "    \"max_text_metric_batches_log\": max_text_metric_batches_log,\n",
        "    \"max_text_metric_batches_eval\": max_text_metric_batches_eval,\n",
        "    \"enable_comet\": bool(enable_comet),\n",
        "}\n",
        "config_path.write_text(pyjson.dumps(run_config, indent=2), encoding=\"utf-8\")\n",
        "\n",
        "print(f\"run_id: {run_id}\")\n",
        "print(f\"run_dir: {run_dir}\")\n",
        "print(f\"ckpt_root: {ckpt_root}\")\n",
        "\n",
        "assert \"_load_text_metrics\" in globals(), \"Run helper-functions cell (Micro-step 21a) first\"\n",
        "assert \"_eval_val_loss\" in globals(), \"Run helper-functions cell (Micro-step 21a) first\"\n",
        "assert \"_eval_text_metrics\" in globals(), \"Run helper-functions cell (Micro-step 21a) first\"\n",
        "assert \"_save_checkpoint\" in globals(), \"Run helper-functions cell (Micro-step 21a) first\"\n",
        "bleu_metric, chrf_metric, comet_metric = _load_text_metrics(enable_comet=enable_comet)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49000b79",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training state\n",
        "model.train()\n",
        "optimizer.zero_grad(set_to_none=True)\n",
        "train_metrics_log = []\n",
        "eval_metrics_log = []\n",
        "best_val_loss = float(\"inf\")\n",
        "optimizer_steps_done = 0\n",
        "micro_step = 0\n",
        "start_time = time.time()\n",
        "interval_start = start_time\n",
        "interval_raw_loss_sum = 0.0\n",
        "interval_micro_steps = 0\n",
        "interval_opt_steps = 0\n",
        "saved_ckpts = []\n",
        "\n",
        "while optimizer_steps_done < max_steps:\n",
        "    for batch in train_loader:\n",
        "        if optimizer_steps_done >= max_steps:\n",
        "            break\n",
        "\n",
        "        micro_step += 1\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "\n",
        "        if use_fp16:\n",
        "            with torch.amp.autocast(device_type=\"cuda\", dtype=torch.float16):\n",
        "                out = model(**batch)\n",
        "                scaled_loss = out.loss / gradient_accumulation_steps\n",
        "            grad_scaler.scale(scaled_loss).backward()\n",
        "        else:\n",
        "            out = model(**batch)\n",
        "            scaled_loss = out.loss / gradient_accumulation_steps\n",
        "            scaled_loss.backward()\n",
        "\n",
        "        raw_loss = float(out.loss.detach().cpu().item())\n",
        "        interval_raw_loss_sum += raw_loss\n",
        "        interval_micro_steps += 1\n",
        "\n",
        "        # One optimizer update happens after N micro-batches (gradient accumulation).\n",
        "        if micro_step % gradient_accumulation_steps == 0:\n",
        "            if use_fp16:\n",
        "                grad_scaler.unscale_(optimizer)\n",
        "            grad_norm = float(torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0).detach().cpu().item())\n",
        "\n",
        "            if use_fp16:\n",
        "                grad_scaler.step(optimizer)\n",
        "                grad_scaler.update()\n",
        "            else:\n",
        "                optimizer.step()\n",
        "\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "            lr_scheduler.step()\n",
        "            optimizer_steps_done += 1\n",
        "            interval_opt_steps += 1\n",
        "\n",
        "            current_lr = float(optimizer.param_groups[0][\"lr\"])\n",
        "            examples_seen = int(optimizer_steps_done * per_device_train_batch_size * gradient_accumulation_steps)\n",
        "            approx_epochs = examples_seen / len(train_df) if len(train_df) else float(\"nan\")\n",
        "\n",
        "            # Interval logging is based on optimizer steps (not micro-steps).\n",
        "            if optimizer_steps_done % log_every_steps == 0 or optimizer_steps_done == 1:\n",
        "                interval_elapsed = time.time() - interval_start\n",
        "                avg_interval_loss = interval_raw_loss_sum / max(1, interval_micro_steps)\n",
        "                steps_per_sec = interval_opt_steps / interval_elapsed if interval_elapsed > 0 else 0.0\n",
        "                sec_per_step = 1.0 / steps_per_sec if steps_per_sec > 0 else float(\"inf\")\n",
        "\n",
        "                mem_alloc_gb = None\n",
        "                mem_peak_gb = None\n",
        "                if torch.cuda.is_available():\n",
        "                    mem_alloc_gb = torch.cuda.memory_allocated(device) / (1024**3)\n",
        "                    mem_peak_gb = torch.cuda.max_memory_allocated(device) / (1024**3)\n",
        "\n",
        "                print(\"=\" * 88)\n",
        "                print(f\"step {optimizer_steps_done:>6}/{max_steps} | avg_loss={avg_interval_loss:.4f} | lr={current_lr:.6g} | grad_norm={grad_norm:.4f}\")\n",
        "                print(f\"interval_sec={interval_elapsed:.2f} | steps/sec={steps_per_sec:.4f} | sec/step={sec_per_step:.4f}\")\n",
        "                print(f\"examples_seen={examples_seen:,} | approx_epochs={approx_epochs:.4f}\")\n",
        "                print(f\"batch_shapes input={tuple(batch['input_ids'].shape)} labels={tuple(batch['labels'].shape)}\")\n",
        "                if mem_alloc_gb is not None:\n",
        "                    print(f\"cuda_mem_alloc_gb={mem_alloc_gb:.3f} | cuda_mem_peak_gb={mem_peak_gb:.3f}\")\n",
        "\n",
        "                text_log_t0 = time.time()\n",
        "                text_metrics_log = _eval_text_metrics(\n",
        "                    model,\n",
        "                    hf_tokenizer,\n",
        "                    val_df,\n",
        "                    device,\n",
        "                    per_device_train_batch_size,\n",
        "                    max_text_metric_batches_log,\n",
        "                    text_metric_num_beams,\n",
        "                    _seed=RANDOM_SEED + optimizer_steps_done,\n",
        "                    _bleu_metric=bleu_metric,\n",
        "                    _chrf_metric=chrf_metric,\n",
        "                    _comet_metric=comet_metric,\n",
        "                )\n",
        "                text_log_sec = time.time() - text_log_t0\n",
        "                print(\n",
        "                    f\"[text@log] samples={text_metrics_log['num_samples']} | bleu={text_metrics_log['bleu']:.3f} \"\n",
        "                    f\"| chrf={text_metrics_log['chrf']:.3f} | comet={text_metrics_log['comet']:.3f} \"\n",
        "                    f\"| text_eval_sec={text_log_sec:.2f}\"\n",
        "                )\n",
        "\n",
        "                train_metrics_log.append({\n",
        "                    \"step\": int(optimizer_steps_done),\n",
        "                    \"avg_interval_loss\": float(avg_interval_loss),\n",
        "                    \"lr\": current_lr,\n",
        "                    \"grad_norm\": grad_norm,\n",
        "                    \"interval_sec\": float(interval_elapsed),\n",
        "                    \"steps_per_sec\": float(steps_per_sec),\n",
        "                    \"sec_per_step\": float(sec_per_step),\n",
        "                    \"examples_seen\": int(examples_seen),\n",
        "                    \"approx_epochs\": float(approx_epochs),\n",
        "                    \"batch_input_len\": int(batch[\"input_ids\"].shape[1]),\n",
        "                    \"batch_label_len\": int(batch[\"labels\"].shape[1]),\n",
        "                    \"cuda_mem_alloc_gb\": float(mem_alloc_gb) if mem_alloc_gb is not None else None,\n",
        "                    \"cuda_mem_peak_gb\": float(mem_peak_gb) if mem_peak_gb is not None else None,\n",
        "                    \"text_eval_sec\": float(text_log_sec),\n",
        "                    \"text_samples\": int(text_metrics_log[\"num_samples\"]),\n",
        "                    \"text_batches\": int(text_metrics_log[\"num_batches\"]),\n",
        "                    \"bleu\": float(text_metrics_log[\"bleu\"]),\n",
        "                    \"chrf\": float(text_metrics_log[\"chrf\"]),\n",
        "                    \"comet\": float(text_metrics_log[\"comet\"]),\n",
        "                    \"bleu_en_to_ar\": float(text_metrics_log[\"bleu_en_to_ar\"]),\n",
        "                    \"bleu_ar_to_en\": float(text_metrics_log[\"bleu_ar_to_en\"]),\n",
        "                    \"chrf_en_to_ar\": float(text_metrics_log[\"chrf_en_to_ar\"]),\n",
        "                    \"chrf_ar_to_en\": float(text_metrics_log[\"chrf_ar_to_en\"]),\n",
        "                })\n",
        "                pd.DataFrame(train_metrics_log).to_csv(train_metrics_path, index=False)\n",
        "\n",
        "                interval_start = time.time()\n",
        "                interval_raw_loss_sum = 0.0\n",
        "                interval_micro_steps = 0\n",
        "                interval_opt_steps = 0\n",
        "\n",
        "            # Run validation periodically and always at the final step.\n",
        "            should_eval = (optimizer_steps_done % eval_every_steps == 0) or (optimizer_steps_done == max_steps)\n",
        "            if should_eval:\n",
        "                val_loss = _eval_val_loss(model, val_loader, device, use_fp16, max_batches=max_val_batches)\n",
        "                text_eval_t0 = time.time()\n",
        "                text_metrics_eval = _eval_text_metrics(\n",
        "                    model,\n",
        "                    hf_tokenizer,\n",
        "                    val_df,\n",
        "                    device,\n",
        "                    per_device_train_batch_size,\n",
        "                    max_text_metric_batches_eval,\n",
        "                    text_metric_num_beams,\n",
        "                    _seed=RANDOM_SEED + 10_000 + optimizer_steps_done,\n",
        "                    _bleu_metric=bleu_metric,\n",
        "                    _chrf_metric=chrf_metric,\n",
        "                    _comet_metric=comet_metric,\n",
        "                )\n",
        "                text_eval_sec = time.time() - text_eval_t0\n",
        "                print(\n",
        "                    f\"[eval] step={optimizer_steps_done} val_loss={val_loss:.4f} | \"\n",
        "                    f\"bleu={text_metrics_eval['bleu']:.3f} | chrf={text_metrics_eval['chrf']:.3f} | \"\n",
        "                    f\"comet={text_metrics_eval['comet']:.3f} | text_eval_sec={text_eval_sec:.2f}\"\n",
        "                )\n",
        "                eval_metrics_log.append({\n",
        "                    \"step\": int(optimizer_steps_done),\n",
        "                    \"val_loss\": float(val_loss),\n",
        "                    \"lr\": current_lr,\n",
        "                    \"text_eval_sec\": float(text_eval_sec),\n",
        "                    \"text_samples\": int(text_metrics_eval[\"num_samples\"]),\n",
        "                    \"text_batches\": int(text_metrics_eval[\"num_batches\"]),\n",
        "                    \"bleu\": float(text_metrics_eval[\"bleu\"]),\n",
        "                    \"chrf\": float(text_metrics_eval[\"chrf\"]),\n",
        "                    \"comet\": float(text_metrics_eval[\"comet\"]),\n",
        "                    \"bleu_en_to_ar\": float(text_metrics_eval[\"bleu_en_to_ar\"]),\n",
        "                    \"bleu_ar_to_en\": float(text_metrics_eval[\"bleu_ar_to_en\"]),\n",
        "                    \"chrf_en_to_ar\": float(text_metrics_eval[\"chrf_en_to_ar\"]),\n",
        "                    \"chrf_ar_to_en\": float(text_metrics_eval[\"chrf_ar_to_en\"]),\n",
        "                })\n",
        "                pd.DataFrame(eval_metrics_log).to_csv(eval_metrics_path, index=False)\n",
        "\n",
        "                if np.isfinite(val_loss) and val_loss < best_val_loss:\n",
        "                    best_val_loss = float(val_loss)\n",
        "                    _save_checkpoint(model, hf_tokenizer, optimizer, lr_scheduler, grad_scaler, optimizer_steps_done, val_loss, best_dir)\n",
        "                    print(f\"[best] new best val_loss={best_val_loss:.4f} saved to {best_dir}\")\n",
        "\n",
        "            # Save periodic checkpoints independently from validation schedule.\n",
        "            should_save = (optimizer_steps_done % save_every_steps == 0) or (optimizer_steps_done == max_steps)\n",
        "            if should_save:\n",
        "                ckpt_dir = ckpt_root / f\"step_{optimizer_steps_done:06d}\"\n",
        "                _save_checkpoint(model, hf_tokenizer, optimizer, lr_scheduler, grad_scaler, optimizer_steps_done, None, ckpt_dir)\n",
        "                saved_ckpts.append(ckpt_dir)\n",
        "                print(f\"[ckpt] saved: {ckpt_dir}\")\n",
        "\n",
        "                # Optional retention policy to limit disk usage.\n",
        "                if keep_last_n_checkpoints is not None and keep_last_n_checkpoints > 0:\n",
        "                    while len(saved_ckpts) > keep_last_n_checkpoints:\n",
        "                        old = saved_ckpts.pop(0)\n",
        "                        if old.exists():\n",
        "                            shutil.rmtree(old)\n",
        "                            print(f\"[ckpt] removed old checkpoint: {old}\")\n",
        "\n",
        "total_elapsed = time.time() - start_time\n",
        "print(\"=\" * 88)\n",
        "print(f\"Training finished at step {optimizer_steps_done}/{max_steps}\")\n",
        "print(f\"Total elapsed sec: {total_elapsed:.2f}\")\n",
        "print(f\"Best val loss: {best_val_loss if np.isfinite(best_val_loss) else None}\")\n",
        "print(f\"Train metrics CSV: {train_metrics_path}\")\n",
        "print(f\"Eval metrics CSV: {eval_metrics_path}\")\n",
        "print(f\"Best model dir: {best_dir}\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
