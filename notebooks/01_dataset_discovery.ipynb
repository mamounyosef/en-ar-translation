{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "bedd9c72",
      "metadata": {},
      "source": [
        "# EN-AR Dataset Discovery\n",
        "\n",
        "## Objective\n",
        "- Build a clean EN-AR discovery dataset from trusted sources only.\n",
        "- Sources used here: local 25k CSV + Hugging Face `ds2`, `ds3`, and `df4` parquet.\n",
        "- Inspect Hugging Face schemas first, then select EN/AR columns before merge.\n",
        "\n",
        "## Scope for This Notebook\n",
        "- EDA only.\n",
        "- No model training in this notebook.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "d76a3676",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Project root: c:\\My Projects\\en-ar-translation\n",
            "Local 25k CSV path: c:\\My Projects\\en-ar-translation\\dataset\\The Arabic-English Sentence Bank 25k\\arabic_english_sentences.csv\n",
            "Local ds5 CSV path: c:\\My Projects\\en-ar-translation\\dataset\\translation-english-arabic.csv\n",
            "EDA output dir: c:\\My Projects\\en-ar-translation\\artifacts\\eda\n"
          ]
        }
      ],
      "source": [
        "# Setup: imports and constants\n",
        "from __future__ import annotations\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datasets import load_dataset\n",
        "\n",
        "RANDOM_SEED = 42\n",
        "np.random.seed(RANDOM_SEED)\n",
        "\n",
        "candidate_roots = [Path.cwd(), Path.cwd().parent]\n",
        "PROJECT_ROOT = next((r for r in candidate_roots if (r / \"dataset\").exists()), Path.cwd())\n",
        "\n",
        "LOCAL_25K_CSV_PATH = PROJECT_ROOT / \"dataset\" / \"The Arabic-English Sentence Bank 25k\" / \"arabic_english_sentences.csv\"\n",
        "LOCAL_DS5_CSV_PATH = PROJECT_ROOT / \"dataset\" / \"translation-english-arabic.csv\"\n",
        "EDA_OUTPUT_DIR = PROJECT_ROOT / \"artifacts\" / \"eda\"\n",
        "REQUIRED_COLUMNS = [\"en\", \"ar\"]\n",
        "MAX_SEQ_LEN = 128\n",
        "\n",
        "print(f\"Project root: {PROJECT_ROOT}\")\n",
        "print(f\"Local 25k CSV path: {LOCAL_25K_CSV_PATH}\")\n",
        "print(f\"Local ds5 CSV path: {LOCAL_DS5_CSV_PATH}\")\n",
        "print(f\"EDA output dir: {EDA_OUTPUT_DIR}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "a1329c11",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Local 25k dataset found: c:\\My Projects\\en-ar-translation\\dataset\\The Arabic-English Sentence Bank 25k\\arabic_english_sentences.csv\n",
            "Local ds5 dataset found: c:\\My Projects\\en-ar-translation\\dataset\\translation-english-arabic.csv\n"
          ]
        }
      ],
      "source": [
        "# Validate required local dataset files\n",
        "assert LOCAL_25K_CSV_PATH.exists(), f\"Local 25k CSV not found: {LOCAL_25K_CSV_PATH}\"\n",
        "assert LOCAL_DS5_CSV_PATH.exists(), f\"Local ds5 CSV not found: {LOCAL_DS5_CSV_PATH}\"\n",
        "print(f\"Local 25k dataset found: {LOCAL_25K_CSV_PATH}\")\n",
        "print(f\"Local ds5 dataset found: {LOCAL_DS5_CSV_PATH}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a103b6f8",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded ds2 splits: ['train']\n",
            "Loaded ds3 splits: ['train']\n",
            "Loaded ds4 splits: ['train', 'validation', 'test']\n",
            "Loaded ds5 rows: 34,912\n"
          ]
        }
      ],
      "source": [
        "# Load ds2/ds3/ds4 from Hugging Face and ds5 from local CSV\n",
        "ds2 = load_dataset(\"Arabic-Clip-Archive/ImageCaptions-7M-Translations-Arabic\")\n",
        "ds3 = load_dataset(\"salehalmansour/english-to-arabic-translate\")\n",
        "ds4 = load_dataset(\"ammagra/english-arabic-speech-translation\")\n",
        "ds5 = pd.read_csv(LOCAL_DS5_CSV_PATH, encoding=\"utf-8\")\n",
        "\n",
        "print(\"Loaded ds2 splits:\", list(ds2.keys()))\n",
        "print(\"Loaded ds3 splits:\", list(ds3.keys()))\n",
        "print(\"Loaded ds4 splits:\", list(ds4.keys()))\n",
        "print(f\"Loaded ds5 rows: {len(ds5):,}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "011ee749",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ds2 splits: ['train']\n",
            "- ds2[train] rows: 150,000\n",
            "  columns: ['caption', 'caption_sv', 'caption_multi', 'url', 'multi_language_code', 'multi_language_name', 'multiple_target_model', 'target_code', 'opus_mt_url', 'index']\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>caption</th>\n",
              "      <th>caption_sv</th>\n",
              "      <th>caption_multi</th>\n",
              "      <th>url</th>\n",
              "      <th>multi_language_code</th>\n",
              "      <th>multi_language_name</th>\n",
              "      <th>multiple_target_model</th>\n",
              "      <th>target_code</th>\n",
              "      <th>opus_mt_url</th>\n",
              "      <th>index</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>sheep eating on grass outside of a barn in the...</td>\n",
              "      <td>får som äter på gräs utanför en lada mitt på e...</td>\n",
              "      <td>الخراف تأكل على العشب خارج الحظيرة في وسط حقل</td>\n",
              "      <td>http://l7.alamy.com/zooms/caadcbc0b3cd43baa411...</td>\n",
              "      <td>ar</td>\n",
              "      <td>arabic</td>\n",
              "      <td>1</td>\n",
              "      <td>ara</td>\n",
              "      <td>Helsinki-NLP/opus-mt-en-ar</td>\n",
              "      <td>450001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>man in the cinema with popcorn and a cell phone</td>\n",
              "      <td>man på bio med popcorn och en mobiltelefon</td>\n",
              "      <td>رجل في السينما مع الفشار وهاتف خلوي</td>\n",
              "      <td>http://l7.alamy.com/zooms/05280780b00f426d85fa...</td>\n",
              "      <td>ar</td>\n",
              "      <td>arabic</td>\n",
              "      <td>1</td>\n",
              "      <td>ara</td>\n",
              "      <td>Helsinki-NLP/opus-mt-en-ar</td>\n",
              "      <td>450002</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             caption  \\\n",
              "0  sheep eating on grass outside of a barn in the...   \n",
              "1    man in the cinema with popcorn and a cell phone   \n",
              "\n",
              "                                          caption_sv  \\\n",
              "0  får som äter på gräs utanför en lada mitt på e...   \n",
              "1         man på bio med popcorn och en mobiltelefon   \n",
              "\n",
              "                                   caption_multi  \\\n",
              "0  الخراف تأكل على العشب خارج الحظيرة في وسط حقل   \n",
              "1            رجل في السينما مع الفشار وهاتف خلوي   \n",
              "\n",
              "                                                 url multi_language_code  \\\n",
              "0  http://l7.alamy.com/zooms/caadcbc0b3cd43baa411...                  ar   \n",
              "1  http://l7.alamy.com/zooms/05280780b00f426d85fa...                  ar   \n",
              "\n",
              "  multi_language_name  multiple_target_model target_code  \\\n",
              "0              arabic                      1         ara   \n",
              "1              arabic                      1         ara   \n",
              "\n",
              "                  opus_mt_url   index  \n",
              "0  Helsinki-NLP/opus-mt-en-ar  450001  \n",
              "1  Helsinki-NLP/opus-mt-en-ar  450002  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ds3 splits: ['train']\n",
            "- ds3[train] rows: 1,325,899\n",
            "  columns: ['en', 'ar']\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>en</th>\n",
              "      <th>ar</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>and this</td>\n",
              "      <td>و هذه؟</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>it was um</td>\n",
              "      <td>...لقد كان</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          en          ar\n",
              "0   and this      و هذه؟\n",
              "1  it was um  ...لقد كان"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ds4 splits: ['train', 'validation', 'test']\n",
            "- ds4[train] rows: 260,487\n",
            "  columns: ['client_id', 'file', 'audio', 'sentence', 'translation', 'id']\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>client_id</th>\n",
              "      <th>file</th>\n",
              "      <th>audio</th>\n",
              "      <th>sentence</th>\n",
              "      <th>translation</th>\n",
              "      <th>id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>69a495674a7d640f049bbe552424f75dc1263ecc706b49...</td>\n",
              "      <td>/content/cv4-en/clips/common_voice_en_19786080...</td>\n",
              "      <td>{'bytes': b'ID3\\x04\\x00\\x00\\x00\\x00\\x00#TSSE\\x...</td>\n",
              "      <td>For around a decade Ivens lived in Eastern Eur...</td>\n",
              "      <td>عاش إيفينز في أوروبا الشرقية لما يُقارب من عقد...</td>\n",
              "      <td>common_voice_en_19786080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>c5d41c1cf20243babd6d9650ee3c6a65b13fb743953450...</td>\n",
              "      <td>/content/cv4-en/clips/common_voice_en_18664696...</td>\n",
              "      <td>{'bytes': b'ID3\\x04\\x00\\x00\\x00\\x00\\x00#TSSE\\x...</td>\n",
              "      <td>I almost forgive you the fright you gave me!</td>\n",
              "      <td>لقد سامحتك تقريبا على الرعب الذي سببته لي!</td>\n",
              "      <td>common_voice_en_18664696</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           client_id  \\\n",
              "0  69a495674a7d640f049bbe552424f75dc1263ecc706b49...   \n",
              "1  c5d41c1cf20243babd6d9650ee3c6a65b13fb743953450...   \n",
              "\n",
              "                                                file  \\\n",
              "0  /content/cv4-en/clips/common_voice_en_19786080...   \n",
              "1  /content/cv4-en/clips/common_voice_en_18664696...   \n",
              "\n",
              "                                               audio  \\\n",
              "0  {'bytes': b'ID3\\x04\\x00\\x00\\x00\\x00\\x00#TSSE\\x...   \n",
              "1  {'bytes': b'ID3\\x04\\x00\\x00\\x00\\x00\\x00#TSSE\\x...   \n",
              "\n",
              "                                            sentence  \\\n",
              "0  For around a decade Ivens lived in Eastern Eur...   \n",
              "1       I almost forgive you the fright you gave me!   \n",
              "\n",
              "                                         translation                        id  \n",
              "0  عاش إيفينز في أوروبا الشرقية لما يُقارب من عقد...  common_voice_en_19786080  \n",
              "1         لقد سامحتك تقريبا على الرعب الذي سببته لي!  common_voice_en_18664696  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "- ds4[validation] rows: 26,049\n",
            "  columns: ['client_id', 'file', 'audio', 'sentence', 'translation', 'id']\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>client_id</th>\n",
              "      <th>file</th>\n",
              "      <th>audio</th>\n",
              "      <th>sentence</th>\n",
              "      <th>translation</th>\n",
              "      <th>id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1e95bfcdd92ff136ab9d0501627c13866a00abbd3bda56...</td>\n",
              "      <td>/content/cv4-en/clips/common_voice_en_18664843...</td>\n",
              "      <td>{'bytes': b'ID3\\x04\\x00\\x00\\x00\\x00\\x00#TSSE\\x...</td>\n",
              "      <td>The key of the back door, sir?</td>\n",
              "      <td>مفتاح الباب الخلفي يا سيدي؟</td>\n",
              "      <td>common_voice_en_18664843</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>b28f486b414dbb5ffd2c3f8065c5ddbd9ac0a1e05c191d...</td>\n",
              "      <td>/content/cv4-en/clips/common_voice_en_19195751...</td>\n",
              "      <td>{'bytes': b'ID3\\x04\\x00\\x00\\x00\\x00\\x00#TSSE\\x...</td>\n",
              "      <td>Completed and rigged bombs were found in Nebra...</td>\n",
              "      <td>تم العثور على قنابل جاهزة للاستعمال و مقلدة في...</td>\n",
              "      <td>common_voice_en_19195751</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           client_id  \\\n",
              "0  1e95bfcdd92ff136ab9d0501627c13866a00abbd3bda56...   \n",
              "1  b28f486b414dbb5ffd2c3f8065c5ddbd9ac0a1e05c191d...   \n",
              "\n",
              "                                                file  \\\n",
              "0  /content/cv4-en/clips/common_voice_en_18664843...   \n",
              "1  /content/cv4-en/clips/common_voice_en_19195751...   \n",
              "\n",
              "                                               audio  \\\n",
              "0  {'bytes': b'ID3\\x04\\x00\\x00\\x00\\x00\\x00#TSSE\\x...   \n",
              "1  {'bytes': b'ID3\\x04\\x00\\x00\\x00\\x00\\x00#TSSE\\x...   \n",
              "\n",
              "                                            sentence  \\\n",
              "0                     The key of the back door, sir?   \n",
              "1  Completed and rigged bombs were found in Nebra...   \n",
              "\n",
              "                                         translation                        id  \n",
              "0                        مفتاح الباب الخلفي يا سيدي؟  common_voice_en_18664843  \n",
              "1  تم العثور على قنابل جاهزة للاستعمال و مقلدة في...  common_voice_en_19195751  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "- ds4[test] rows: 15,531\n",
            "  columns: ['client_id', 'file', 'audio', 'sentence', 'translation', 'id']\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>client_id</th>\n",
              "      <th>file</th>\n",
              "      <th>audio</th>\n",
              "      <th>sentence</th>\n",
              "      <th>translation</th>\n",
              "      <th>id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0013037a1d45cc33460806cc3f8ecee9d536c45639ba4c...</td>\n",
              "      <td>/content/cv4-en/clips/common_voice_en_699711.mp3</td>\n",
              "      <td>{'bytes': b'ID3\\x04\\x00\\x00\\x00\\x00\\x00\\x17TSS...</td>\n",
              "      <td>\"She'll be all right.\"</td>\n",
              "      <td>ستكون بخير.</td>\n",
              "      <td>common_voice_en_699711</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>001509f4624a7dee75247f6a8b642c4a0d09f8be3eeea6...</td>\n",
              "      <td>/content/cv4-en/clips/common_voice_en_18132047...</td>\n",
              "      <td>{'bytes': b'ID3\\x04\\x00\\x00\\x00\\x00\\x00#TSSE\\x...</td>\n",
              "      <td>\"All's well that ends well.\"</td>\n",
              "      <td>الأمور بخواتمها.</td>\n",
              "      <td>common_voice_en_18132047</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           client_id  \\\n",
              "0  0013037a1d45cc33460806cc3f8ecee9d536c45639ba4c...   \n",
              "1  001509f4624a7dee75247f6a8b642c4a0d09f8be3eeea6...   \n",
              "\n",
              "                                                file  \\\n",
              "0   /content/cv4-en/clips/common_voice_en_699711.mp3   \n",
              "1  /content/cv4-en/clips/common_voice_en_18132047...   \n",
              "\n",
              "                                               audio  \\\n",
              "0  {'bytes': b'ID3\\x04\\x00\\x00\\x00\\x00\\x00\\x17TSS...   \n",
              "1  {'bytes': b'ID3\\x04\\x00\\x00\\x00\\x00\\x00#TSSE\\x...   \n",
              "\n",
              "                       sentence       translation                        id  \n",
              "0        \"She'll be all right.\"       ستكون بخير.    common_voice_en_699711  \n",
              "1  \"All's well that ends well.\"  الأمور بخواتمها.  common_voice_en_18132047  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ds5 schema:\n",
            "- rows: 34,912\n",
            "- columns: ['english', 'arabic']\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>english</th>\n",
              "      <th>arabic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Hi.</td>\n",
              "      <td>مرحبًا.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Run!</td>\n",
              "      <td>اركض!</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  english   arabic\n",
              "0     Hi.  مرحبًا.\n",
              "1    Run!    اركض!"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Inspect ds2/ds3/ds4 (DatasetDict) and ds5 (DataFrame) schema to choose EN/AR columns\n",
        "def inspect_dataset_dict(ds, name: str, preview_rows: int = 2) -> None:\n",
        "    print(f\"\\n{name} splits: {list(ds.keys())}\")\n",
        "    for split_name, split_ds in ds.items():\n",
        "        print(f\"- {name}[{split_name}] rows: {len(split_ds):,}\")\n",
        "        print(f\"  columns: {split_ds.column_names}\")\n",
        "        if len(split_ds) > 0:\n",
        "            preview_df = split_ds.select(range(min(preview_rows, len(split_ds)))).to_pandas()\n",
        "            display(preview_df.head(preview_rows))\n",
        "\n",
        "inspect_dataset_dict(ds2, \"ds2\")\n",
        "inspect_dataset_dict(ds3, \"ds3\")\n",
        "inspect_dataset_dict(ds4, \"ds4\")\n",
        "\n",
        "print(\"\\nds5 schema:\")\n",
        "print(\"- rows:\", f\"{len(ds5):,}\")\n",
        "print(\"- columns:\", list(ds5.columns))\n",
        "display(ds5.head(2))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "ea92db6c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "local_25k rows: 25,000\n",
            "ds2[train] -> rows=150,000, en_col=caption, ar_col=caption_multi\n",
            "ds2 total rows used: 150,000\n",
            "ds3[train] -> rows=412,000, en_col=en, ar_col=ar\n",
            "ds3 total rows used: 412,000\n",
            "ds4[train] -> rows=260,487, en_col=sentence, ar_col=translation\n",
            "ds4[validation] -> rows=26,049, en_col=sentence, ar_col=translation\n",
            "ds4[test] -> rows=15,531, en_col=sentence, ar_col=translation\n",
            "ds4 total rows used: 302,067\n",
            "ds5 -> rows=34,912, en_col=english, ar_col=arabic\n",
            "ds5 total rows used: 34,912\n"
          ]
        }
      ],
      "source": [
        "# Choose columns and build standardized EN/AR dataframes (ds2/ds3/ds4/ds5)\n",
        "# Set these manually after schema inspection if auto-detection is wrong.\n",
        "DS2_EN_COL = \"caption\"\n",
        "DS2_AR_COL = \"caption_multi\"\n",
        "DS3_EN_COL = \"en\"\n",
        "DS3_AR_COL = \"ar\"\n",
        "DS4_EN_COL = \"sentence\"\n",
        "DS4_AR_COL = \"translation\"\n",
        "DS5_EN_COL = \"english\"\n",
        "DS5_AR_COL = \"arabic\"\n",
        "\n",
        "# Row caps\n",
        "DS2_MAX_ROWS = None\n",
        "DS3_MAX_ROWS = 412_000\n",
        "DS4_MAX_ROWS = None\n",
        "DS5_MAX_ROWS = None\n",
        "\n",
        "EN_CANDIDATES = [\"en\", \"english\", \"eng\", \"source\", \"src\", \"text_en\", \"sentence_en\", \"input\", \"caption\"]\n",
        "AR_CANDIDATES = [\"ar\", \"arabic\", \"target\", \"tgt\", \"text_ar\", \"sentence_ar\", \"output\", \"caption_multi\", \"translation\"]\n",
        "\n",
        "def pick_column(column_names, preferred, candidates, side_name):\n",
        "    cols = list(column_names)\n",
        "    if preferred is not None:\n",
        "        assert preferred in cols, f\"{side_name} column `{preferred}` not found. Available: {cols}\"\n",
        "        return preferred\n",
        "    for cand in candidates:\n",
        "        if cand in cols:\n",
        "            return cand\n",
        "    raise ValueError(f\"Could not infer {side_name} column. Available: {cols}. Set it manually in config.\")\n",
        "\n",
        "def dataset_dict_to_en_ar(ds, preferred_en, preferred_ar, max_rows, name):\n",
        "    frames = []\n",
        "    used = 0\n",
        "    for split_name, split_ds in ds.items():\n",
        "        chosen_en = pick_column(split_ds.column_names, preferred_en, EN_CANDIDATES, f\"{name} EN\")\n",
        "        chosen_ar = pick_column(split_ds.column_names, preferred_ar, AR_CANDIDATES, f\"{name} AR\")\n",
        "        split_df = split_ds.to_pandas()[[chosen_en, chosen_ar]].rename(columns={chosen_en: \"en\", chosen_ar: \"ar\"})\n",
        "        if max_rows is not None:\n",
        "            remaining = max_rows - used\n",
        "            if remaining <= 0:\n",
        "                break\n",
        "            split_df = split_df.head(remaining).copy()\n",
        "        used += len(split_df)\n",
        "        frames.append(split_df)\n",
        "        print(f\"{name}[{split_name}] -> rows={len(split_df):,}, en_col={chosen_en}, ar_col={chosen_ar}\")\n",
        "    if not frames:\n",
        "        raise ValueError(f\"No rows collected from {name}.\")\n",
        "    return pd.concat(frames, ignore_index=True)\n",
        "\n",
        "def dataframe_to_en_ar(df_in, preferred_en, preferred_ar, max_rows, name):\n",
        "    chosen_en = pick_column(df_in.columns, preferred_en, EN_CANDIDATES, f\"{name} EN\")\n",
        "    chosen_ar = pick_column(df_in.columns, preferred_ar, AR_CANDIDATES, f\"{name} AR\")\n",
        "    df_out = df_in[[chosen_en, chosen_ar]].rename(columns={chosen_en: \"en\", chosen_ar: \"ar\"}).copy()\n",
        "    if max_rows is not None:\n",
        "        df_out = df_out.head(max_rows).copy()\n",
        "    print(f\"{name} -> rows={len(df_out):,}, en_col={chosen_en}, ar_col={chosen_ar}\")\n",
        "    return df_out\n",
        "\n",
        "df_local_25k = pd.read_csv(LOCAL_25K_CSV_PATH, encoding=\"utf-8\")\n",
        "df_local_25k = df_local_25k.rename(columns={\"English\": \"en\", \"Arabic\": \"ar\"})[[\"en\", \"ar\"]]\n",
        "print(f\"local_25k rows: {len(df_local_25k):,}\")\n",
        "\n",
        "df_ds2 = dataset_dict_to_en_ar(ds2, DS2_EN_COL, DS2_AR_COL, DS2_MAX_ROWS, \"ds2\")\n",
        "print(f\"ds2 total rows used: {len(df_ds2):,}\")\n",
        "\n",
        "df_ds3 = dataset_dict_to_en_ar(ds3, DS3_EN_COL, DS3_AR_COL, DS3_MAX_ROWS, \"ds3\")\n",
        "print(f\"ds3 total rows used: {len(df_ds3):,}\")\n",
        "\n",
        "df_ds4 = dataset_dict_to_en_ar(ds4, DS4_EN_COL, DS4_AR_COL, DS4_MAX_ROWS, \"ds4\")\n",
        "print(f\"ds4 total rows used: {len(df_ds4):,}\")\n",
        "\n",
        "df_ds5 = dataframe_to_en_ar(ds5, DS5_EN_COL, DS5_AR_COL, DS5_MAX_ROWS, \"ds5\")\n",
        "print(f\"ds5 total rows used: {len(df_ds5):,}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "111796f2",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Rows by source:\n",
            "- local_25k: 25,000\n",
            "- ds2: 150,000\n",
            "- ds3: 412,000\n",
            "- ds4: 302,067\n",
            "- ds5: 34,912\n",
            "Merged rows (before dedup): 923,979\n",
            "Duplicate pairs before dedup: 95,353 (10.3198%)\n",
            "Rows after dedup: 828,626\n",
            "Columns: ['en', 'ar']\n"
          ]
        }
      ],
      "source": [
        "# Merge all selected datasets and remove exact duplicate EN-AR pairs\n",
        "source_frames = [\n",
        "    (\"local_25k\", df_local_25k),\n",
        "    (\"ds2\", df_ds2),\n",
        "    (\"ds3\", df_ds3),\n",
        "    (\"ds4\", df_ds4),\n",
        "    (\"ds5\", df_ds5),\n",
        "]\n",
        "\n",
        "for name, frame in source_frames:\n",
        "    missing = [c for c in REQUIRED_COLUMNS if c not in frame.columns]\n",
        "    assert not missing, f\"{name} is missing columns: {missing}\"\n",
        "\n",
        "df_merged = pd.concat([f for _, f in source_frames], ignore_index=True)\n",
        "rows_before_dedup = len(df_merged)\n",
        "unique_pairs_before = df_merged.drop_duplicates(subset=REQUIRED_COLUMNS).shape[0]\n",
        "duplicate_pairs_before = rows_before_dedup - unique_pairs_before\n",
        "duplicate_ratio_before = duplicate_pairs_before / rows_before_dedup if rows_before_dedup else 0.0\n",
        "\n",
        "df = df_merged.drop_duplicates(subset=REQUIRED_COLUMNS, keep=\"first\").reset_index(drop=True)\n",
        "rows_after_dedup = len(df)\n",
        "\n",
        "print(\"Rows by source:\")\n",
        "for name, frame in source_frames:\n",
        "    print(f\"- {name}: {len(frame):,}\")\n",
        "print(f\"Merged rows (before dedup): {rows_before_dedup:,}\")\n",
        "print(f\"Duplicate pairs before dedup: {duplicate_pairs_before:,} ({duplicate_ratio_before:.4%})\")\n",
        "print(f\"Rows after dedup: {rows_after_dedup:,}\")\n",
        "print(f\"Columns: {list(df.columns)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "62f13a48",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape: (828626, 2)\n",
            "Row count: 828,626\n",
            "Column count: 2\n",
            "Approx memory usage: 231.63 MB\n"
          ]
        }
      ],
      "source": [
        "# Basic shape, row count, and memory footprint\n",
        "row_count, col_count = df.shape\n",
        "memory_mb = df.memory_usage(deep=True).sum() / (1024 ** 2)\n",
        "\n",
        "print(f\"Shape: {df.shape}\")\n",
        "print(f\"Row count: {row_count:,}\")\n",
        "print(f\"Column count: {col_count}\")\n",
        "print(f\"Approx memory usage: {memory_mb:,.2f} MB\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "a35b6f88",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Detected likely swapped rows: 1\n",
            "Rows removed after re-dedup: 0\n",
            "Preview of detected rows before swap (first 10):\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>en</th>\n",
              "      <th>ar</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>780351</th>\n",
              "      <td>راجع به چی حرف میزنی؟</td>\n",
              "      <td>[TO REMOVE]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                           en           ar\n",
              "780351  راجع به چی حرف میزنی؟  [TO REMOVE]"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Detect swapped-language rows (AR in en, EN in ar), fix them, then re-deduplicate\n",
        "en_text = df[\"en\"].fillna(\"\").astype(str)\n",
        "ar_text = df[\"ar\"].fillna(\"\").astype(str)\n",
        "\n",
        "en_has_arabic = en_text.str.contains(r\"[\\u0600-\\u06FF]\", regex=True)\n",
        "en_has_latin = en_text.str.contains(r\"[A-Za-z]\", regex=True)\n",
        "ar_has_arabic = ar_text.str.contains(r\"[\\u0600-\\u06FF]\", regex=True)\n",
        "ar_has_latin = ar_text.str.contains(r\"[A-Za-z]\", regex=True)\n",
        "\n",
        "# Conservative swap rule to reduce false positives\n",
        "swap_mask = en_has_arabic & ar_has_latin & (~en_has_latin | ~ar_has_arabic)\n",
        "swap_count = int(swap_mask.sum())\n",
        "\n",
        "preview_before_swap = df.loc[swap_mask, [\"en\", \"ar\"]].head(10).copy()\n",
        "\n",
        "if swap_count > 0:\n",
        "    df.loc[swap_mask, [\"en\", \"ar\"]] = df.loc[swap_mask, [\"ar\", \"en\"]].values\n",
        "\n",
        "rows_before_rededup = len(df)\n",
        "df = df.drop_duplicates(subset=REQUIRED_COLUMNS, keep=\"first\").reset_index(drop=True)\n",
        "rows_after_rededup = len(df)\n",
        "rededup_removed = rows_before_rededup - rows_after_rededup\n",
        "\n",
        "print(f\"Detected likely swapped rows: {swap_count:,}\")\n",
        "print(f\"Rows removed after re-dedup: {rededup_removed:,}\")\n",
        "print(\"Preview of detected rows before swap (first 10):\")\n",
        "preview_before_swap\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "57bfdb44",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Boundary newline cleanup changes:\n",
            "- en: 54,067 rows updated\n",
            "- ar: 194 rows updated\n"
          ]
        }
      ],
      "source": [
        "# Clean boundary newline markers (literal \"\\n\" and real line breaks and \"-\")\n",
        "newline_clean_stats = {}\n",
        "for col in REQUIRED_COLUMNS:\n",
        "    before_col = df[col].fillna(\"\").astype(str)\n",
        "    after_col = (\n",
        "        before_col\n",
        "        .str.replace(r\"^(?:\\s*\\\\n\\s*|\\s*-\\s*)+\", \"\", regex=True)\n",
        "        .str.replace(r\"(?:\\s*\\\\n\\s*|\\s*-\\s*)+$\", \"\", regex=True)\n",
        "        .str.replace(r\"^[\\r\\n\\-]+\", \"\", regex=True)\n",
        "        .str.replace(r\"[\\r\\n\\-]+$\", \"\", regex=True)\n",
        "        .str.strip()\n",
        "    )\n",
        "    changed_rows = int((before_col != after_col).sum())\n",
        "    newline_clean_stats[col] = changed_rows\n",
        "    df[col] = after_col\n",
        "\n",
        "print(\"Boundary newline cleanup changes:\")\n",
        "for col, count in newline_clean_stats.items():\n",
        "    print(f\"- {col}: {count:,} rows updated\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "id": "9ba8d65e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Rows with Arabic diacritics removed: 85,165\n",
            "Total diacritic characters removed: 136,473\n",
            "Rows removed after re-dedup: 1,050\n"
          ]
        }
      ],
      "source": [
        "# Remove Arabic diacritics from the Arabic column\n",
        "arabic_diacritics_pattern = r\"[\\u0610-\\u061A\\u064B-\\u065F\\u0670\\u06D6-\\u06ED]\"\n",
        "before_ar = df[\"ar\"].fillna(\"\").astype(str)\n",
        "diacritics_removed_chars = int(before_ar.str.count(arabic_diacritics_pattern).sum())\n",
        "after_ar = before_ar.str.replace(arabic_diacritics_pattern, \"\", regex=True)\n",
        "changed_rows = int((before_ar != after_ar).sum())\n",
        "df[\"ar\"] = after_ar.str.replace(r\"\\s+\", \" \", regex=True).str.strip()\n",
        "\n",
        "rows_before_rededup = len(df)\n",
        "df = df.drop_duplicates(subset=REQUIRED_COLUMNS, keep=\"first\").reset_index(drop=True)\n",
        "rows_after_rededup = len(df)\n",
        "\n",
        "print(f\"Rows with Arabic diacritics removed: {changed_rows:,}\")\n",
        "print(f\"Total diacritic characters removed: {diacritics_removed_chars:,}\")\n",
        "print(f\"Rows removed after re-dedup: {rows_before_rededup - rows_after_rededup:,}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "id": "fbb093b6",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>null_count</th>\n",
              "      <th>empty_or_whitespace_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>en</th>\n",
              "      <td>0</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ar</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    null_count  empty_or_whitespace_count\n",
              "en           0                         28\n",
              "ar           0                          2"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Null and empty-row checks\n",
        "null_counts = df[REQUIRED_COLUMNS].isna().sum()\n",
        "empty_counts = {\n",
        "    col: df[col].fillna(\"\").astype(str).str.strip().eq(\"\").sum()\n",
        "    for col in REQUIRED_COLUMNS\n",
        "}\n",
        "\n",
        "quality_df = pd.DataFrame({\n",
        "    \"null_count\": null_counts,\n",
        "    \"empty_or_whitespace_count\": pd.Series(empty_counts),\n",
        "})\n",
        "quality_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "id": "f0841c18",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total pairs: 827,576\n",
            "Unique pairs: 827,576\n",
            "Duplicate pairs: 0\n",
            "Duplicate ratio: 0.0000%\n"
          ]
        }
      ],
      "source": [
        "# Exact EN-AR pair duplicate ratio after dedup\n",
        "pair_count = len(df)\n",
        "unique_pair_count = df.drop_duplicates(subset=REQUIRED_COLUMNS).shape[0]\n",
        "duplicate_pair_count = pair_count - unique_pair_count\n",
        "duplicate_ratio = duplicate_pair_count / pair_count if pair_count else 0.0\n",
        "\n",
        "print(f\"Total pairs: {pair_count:,}\")\n",
        "print(f\"Unique pairs: {unique_pair_count:,}\")\n",
        "print(f\"Duplicate pairs: {duplicate_pair_count:,}\")\n",
        "print(f\"Duplicate ratio: {duplicate_ratio:.4%}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "id": "8b788290",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unique EN sentences: 770,713\n",
            "Unique AR sentences: 808,937\n",
            "EN uniqueness ratio: 93.1290%\n",
            "AR uniqueness ratio: 97.7478%\n"
          ]
        }
      ],
      "source": [
        "# Unique EN and AR counts\n",
        "unique_en_count = df[\"en\"].nunique(dropna=True)\n",
        "unique_ar_count = df[\"ar\"].nunique(dropna=True)\n",
        "total_rows = len(df)\n",
        "\n",
        "print(f\"Unique EN sentences: {unique_en_count:,}\")\n",
        "print(f\"Unique AR sentences: {unique_ar_count:,}\")\n",
        "print(f\"EN uniqueness ratio: {unique_en_count / total_rows:.4%}\")\n",
        "print(f\"AR uniqueness ratio: {unique_ar_count / total_rows:.4%}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "id": "9101229f",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>en</th>\n",
              "      <th>ar</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>7.91</td>\n",
              "      <td>6.44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>p50</th>\n",
              "      <td>7.00</td>\n",
              "      <td>5.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>p90</th>\n",
              "      <td>13.00</td>\n",
              "      <td>11.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>p95</th>\n",
              "      <td>14.00</td>\n",
              "      <td>13.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>p99</th>\n",
              "      <td>21.00</td>\n",
              "      <td>18.00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         en     ar\n",
              "mean   7.91   6.44\n",
              "p50    7.00   5.00\n",
              "p90   13.00  11.00\n",
              "p95   14.00  13.00\n",
              "p99   21.00  18.00"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# EN/AR word-length statistics\n",
        "en_word_lengths = df[\"en\"].fillna(\"\").astype(str).str.split().str.len()\n",
        "ar_word_lengths = df[\"ar\"].fillna(\"\").astype(str).str.split().str.len()\n",
        "\n",
        "word_length_stats = pd.DataFrame({\n",
        "    \"en\": [\n",
        "        en_word_lengths.mean(),\n",
        "        en_word_lengths.quantile(0.50),\n",
        "        en_word_lengths.quantile(0.90),\n",
        "        en_word_lengths.quantile(0.95),\n",
        "        en_word_lengths.quantile(0.99),\n",
        "    ],\n",
        "    \"ar\": [\n",
        "        ar_word_lengths.mean(),\n",
        "        ar_word_lengths.quantile(0.50),\n",
        "        ar_word_lengths.quantile(0.90),\n",
        "        ar_word_lengths.quantile(0.95),\n",
        "        ar_word_lengths.quantile(0.99),\n",
        "    ],\n",
        "}, index=[\"mean\", \"p50\", \"p90\", \"p95\", \"p99\"]).round(2)\n",
        "\n",
        "word_length_stats\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "id": "b099c095",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(           en       ar\n",
              " mean    42.97    34.93\n",
              " p50     36.00    27.00\n",
              " p90     78.00    64.00\n",
              " p95     88.00    75.00\n",
              " p99    118.00   104.00\n",
              " max   1272.00  1281.00,\n",
              "   side   index  char_len                                               text\n",
              " 0   en  807787      1272  maids in ethiopia are mostly women who come to...\n",
              " 1   ar  807787      1281  الخادمات في اثيوبيا معظمهن من النساء اللاتي يا...)"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# EN/AR character-length statistics + outlier preview\n",
        "en_char_lengths = df[\"en\"].fillna(\"\").astype(str).str.len()\n",
        "ar_char_lengths = df[\"ar\"].fillna(\"\").astype(str).str.len()\n",
        "\n",
        "char_length_stats = pd.DataFrame({\n",
        "    \"en\": [\n",
        "        en_char_lengths.mean(),\n",
        "        en_char_lengths.quantile(0.50),\n",
        "        en_char_lengths.quantile(0.90),\n",
        "        en_char_lengths.quantile(0.95),\n",
        "        en_char_lengths.quantile(0.99),\n",
        "        en_char_lengths.max(),\n",
        "    ],\n",
        "    \"ar\": [\n",
        "        ar_char_lengths.mean(),\n",
        "        ar_char_lengths.quantile(0.50),\n",
        "        ar_char_lengths.quantile(0.90),\n",
        "        ar_char_lengths.quantile(0.95),\n",
        "        ar_char_lengths.quantile(0.99),\n",
        "        ar_char_lengths.max(),\n",
        "    ],\n",
        "}, index=[\"mean\", \"p50\", \"p90\", \"p95\", \"p99\", \"max\"]).round(2)\n",
        "\n",
        "max_en_idx = en_char_lengths.idxmax()\n",
        "max_ar_idx = ar_char_lengths.idxmax()\n",
        "outlier_preview = pd.DataFrame([\n",
        "    {\"side\": \"en\", \"index\": int(max_en_idx), \"char_len\": int(en_char_lengths.loc[max_en_idx]), \"text\": str(df.loc[max_en_idx, \"en\"])[:200]},\n",
        "    {\"side\": \"ar\", \"index\": int(max_ar_idx), \"char_len\": int(ar_char_lengths.loc[max_ar_idx]), \"text\": str(df.loc[max_ar_idx, \"ar\"])[:200]},\n",
        "])\n",
        "\n",
        "char_length_stats, outlier_preview\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "id": "32255d0d",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>ratio</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>en_contains_arabic</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ar_contains_latin</th>\n",
              "      <td>28026</td>\n",
              "      <td>3.3865%</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    count    ratio\n",
              "en_contains_arabic      0     0.0%\n",
              "ar_contains_latin   28026  3.3865%"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Script anomaly checks\n",
        "en_has_arabic = df[\"en\"].fillna(\"\").astype(str).str.contains(r\"[\\u0600-\\u06FF]\", regex=True)\n",
        "ar_has_latin = df[\"ar\"].fillna(\"\").astype(str).str.contains(r\"[A-Za-z]\", regex=True)\n",
        "\n",
        "anomaly_summary = pd.DataFrame({\n",
        "    \"count\": [int(en_has_arabic.sum()), int(ar_has_latin.sum())],\n",
        "    \"ratio\": [float(en_has_arabic.mean()), float(ar_has_latin.mean())],\n",
        "}, index=[\"en_contains_arabic\", \"ar_contains_latin\"])\n",
        "\n",
        "anomaly_summary[\"ratio\"] = (anomaly_summary[\"ratio\"] * 100).round(4).astype(str) + \"%\"\n",
        "anomaly_summary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "id": "07623d11",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MAX_SEQ_LEN reference: 128\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>ratio</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>en_gt_max_len</th>\n",
              "      <td>18</td>\n",
              "      <td>0.0022%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ar_gt_max_len</th>\n",
              "      <td>11</td>\n",
              "      <td>0.0013%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>either_side_gt_max_len</th>\n",
              "      <td>20</td>\n",
              "      <td>0.0024%</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                        count    ratio\n",
              "en_gt_max_len              18  0.0022%\n",
              "ar_gt_max_len              11  0.0013%\n",
              "either_side_gt_max_len     20  0.0024%"
            ]
          },
          "execution_count": 83,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Truncation impact estimate for MAX_SEQ_LEN (word-level proxy)\n",
        "en_token_proxy = df[\"en\"].fillna(\"\").astype(str).str.split().str.len()\n",
        "ar_token_proxy = df[\"ar\"].fillna(\"\").astype(str).str.split().str.len()\n",
        "\n",
        "en_trunc_count = int((en_token_proxy > MAX_SEQ_LEN).sum())\n",
        "ar_trunc_count = int((ar_token_proxy > MAX_SEQ_LEN).sum())\n",
        "either_trunc_count = int(((en_token_proxy > MAX_SEQ_LEN) | (ar_token_proxy > MAX_SEQ_LEN)).sum())\n",
        "total_rows = len(df)\n",
        "\n",
        "truncation_estimate = pd.DataFrame({\n",
        "    \"count\": [en_trunc_count, ar_trunc_count, either_trunc_count],\n",
        "    \"ratio\": [\n",
        "        en_trunc_count / total_rows if total_rows else 0.0,\n",
        "        ar_trunc_count / total_rows if total_rows else 0.0,\n",
        "        either_trunc_count / total_rows if total_rows else 0.0,\n",
        "    ],\n",
        "}, index=[\"en_gt_max_len\", \"ar_gt_max_len\", \"either_side_gt_max_len\"])\n",
        "truncation_estimate[\"ratio\"] = (truncation_estimate[\"ratio\"] * 100).round(4).astype(str) + \"%\"\n",
        "\n",
        "print(f\"MAX_SEQ_LEN reference: {MAX_SEQ_LEN}\")\n",
        "truncation_estimate\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "id": "069121ab",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top 10 EN entries:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>en</th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>im sorry</td>\n",
              "      <td>183</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>thank you</td>\n",
              "      <td>180</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>come on</td>\n",
              "      <td>163</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>oh my god</td>\n",
              "      <td>139</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>i dont know</td>\n",
              "      <td>137</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>what are you talking about</td>\n",
              "      <td>133</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>all right</td>\n",
              "      <td>127</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>thats it</td>\n",
              "      <td>120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>no no</td>\n",
              "      <td>119</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>excuse me</td>\n",
              "      <td>115</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                           en  count\n",
              "0                    im sorry    183\n",
              "1                   thank you    180\n",
              "2                     come on    163\n",
              "3                   oh my god    139\n",
              "4                 i dont know    137\n",
              "5  what are you talking about    133\n",
              "6                   all right    127\n",
              "7                    thats it    120\n",
              "8                       no no    119\n",
              "9                   excuse me    115"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top 10 AR entries:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ar</th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>يا إلهي</td>\n",
              "      <td>116</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>كيف حالك؟</td>\n",
              "      <td>85</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>هذا رائع</td>\n",
              "      <td>68</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>نعم</td>\n",
              "      <td>65</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>أليس كذلك؟</td>\n",
              "      <td>64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>ما الأمر؟</td>\n",
              "      <td>57</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>هل أنت بخير ؟</td>\n",
              "      <td>55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>شكرا لك</td>\n",
              "      <td>54</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>حقا ؟</td>\n",
              "      <td>52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>يا إلهي!</td>\n",
              "      <td>47</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              ar  count\n",
              "0        يا إلهي    116\n",
              "1      كيف حالك؟     85\n",
              "2       هذا رائع     68\n",
              "3            نعم     65\n",
              "4     أليس كذلك؟     64\n",
              "5      ما الأمر؟     57\n",
              "6  هل أنت بخير ؟     55\n",
              "7        شكرا لك     54\n",
              "8          حقا ؟     52\n",
              "9       يا إلهي!     47"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Random sample preview (10 rows):\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>en</th>\n",
              "      <th>ar</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Intra-limb coordination involves the planning ...</td>\n",
              "      <td>ينطوي التآزر بين الأطراف على تخطيط المسارات في...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>to the lambrick foundation</td>\n",
              "      <td>في نخب مؤسسة (لامبريك).</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>whispering he can hear us</td>\n",
              "      <td>إن بإمكانه سماعنا .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A woman is doing inclined dumbbell presses at ...</td>\n",
              "      <td>امرأة تقوم بتمارين الدمبل وهي مائلة في صالة أل...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>step right up we had a winner</td>\n",
              "      <td>يوجد تقدم لدينا فائز</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>well have cos on post</td>\n",
              "      <td>سنحضر ضباط في المكان</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>theres a blue door</td>\n",
              "      <td>هناك باب أزرق</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>a document of the department's operations in t...</td>\n",
              "      <td>وثيقة عن عمليات الإدارة في مكان العمل</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>guano bowls</td>\n",
              "      <td>ذرق طائر</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>two children are standing near a wall, one is ...</td>\n",
              "      <td>طفلان يقفان بالقرب من الجدار أحدهما يمسك بمؤخر...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  en  \\\n",
              "0  Intra-limb coordination involves the planning ...   \n",
              "1                         to the lambrick foundation   \n",
              "2                          whispering he can hear us   \n",
              "3  A woman is doing inclined dumbbell presses at ...   \n",
              "4                      step right up we had a winner   \n",
              "5                              well have cos on post   \n",
              "6                                 theres a blue door   \n",
              "7  a document of the department's operations in t...   \n",
              "8                                        guano bowls   \n",
              "9  two children are standing near a wall, one is ...   \n",
              "\n",
              "                                                  ar  \n",
              "0  ينطوي التآزر بين الأطراف على تخطيط المسارات في...  \n",
              "1                            في نخب مؤسسة (لامبريك).  \n",
              "2                                إن بإمكانه سماعنا .  \n",
              "3  امرأة تقوم بتمارين الدمبل وهي مائلة في صالة أل...  \n",
              "4                               يوجد تقدم لدينا فائز  \n",
              "5                               سنحضر ضباط في المكان  \n",
              "6                                      هناك باب أزرق  \n",
              "7              وثيقة عن عمليات الإدارة في مكان العمل  \n",
              "8                                           ذرق طائر  \n",
              "9  طفلان يقفان بالقرب من الجدار أحدهما يمسك بمؤخر...  "
            ]
          },
          "execution_count": 81,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Top EN/AR frequencies + random sample preview\n",
        "top_en = df[\"en\"].fillna(\"\").astype(str).value_counts().head(10).rename_axis(\"en\").reset_index(name=\"count\")\n",
        "top_ar = df[\"ar\"].fillna(\"\").astype(str).value_counts().head(10).rename_axis(\"ar\").reset_index(name=\"count\")\n",
        "sample_preview = df.sample(n=10)[[\"en\", \"ar\"]].reset_index(drop=True)\n",
        "\n",
        "print(\"Top 10 EN entries:\")\n",
        "display(top_en)\n",
        "print(\"Top 10 AR entries:\")\n",
        "display(top_ar)\n",
        "print(\"Random sample preview (10 rows):\")\n",
        "sample_preview\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "id": "88ff25e8",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved compact EDA artifacts to: c:\\My Projects\\en-ar-translation\\artifacts\\eda\n"
          ]
        }
      ],
      "source": [
        "# Export compact EDA artifacts (stats/tables/samples)\n",
        "EDA_OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "summary = {\n",
        "    \"rows\": int(len(df)),\n",
        "    \"columns\": list(df.columns),\n",
        "    \"max_seq_len_reference\": int(MAX_SEQ_LEN),\n",
        "}\n",
        "\n",
        "# Include commonly computed diagnostics when available in notebook state\n",
        "if \"duplicate_pairs_before\" in globals():\n",
        "    summary[\"duplicate_pairs_before_dedup\"] = int(duplicate_pairs_before)\n",
        "if \"duplicate_ratio_before\" in globals():\n",
        "    summary[\"duplicate_ratio_before_dedup\"] = float(duplicate_ratio_before)\n",
        "if \"swap_count\" in globals():\n",
        "    summary[\"swap_count\"] = int(swap_count)\n",
        "if \"rededup_removed\" in globals():\n",
        "    summary[\"rededup_removed_after_swap\"] = int(rededup_removed)\n",
        "if \"diacritics_removed_chars\" in globals():\n",
        "    summary[\"diacritics_removed_chars\"] = int(diacritics_removed_chars)\n",
        "\n",
        "(pd.Series(summary)).to_json(EDA_OUTPUT_DIR / \"eda_summary.json\", force_ascii=False, indent=2)\n",
        "\n",
        "if \"word_length_stats\" in globals():\n",
        "    word_length_stats.to_csv(EDA_OUTPUT_DIR / \"word_length_stats.csv\", encoding=\"utf-8\")\n",
        "if \"char_length_stats\" in globals():\n",
        "    char_length_stats.to_csv(EDA_OUTPUT_DIR / \"char_length_stats.csv\", encoding=\"utf-8\")\n",
        "if \"anomaly_summary\" in globals():\n",
        "    anomaly_summary.to_csv(EDA_OUTPUT_DIR / \"anomaly_summary.csv\", encoding=\"utf-8\")\n",
        "if \"truncation_estimate\" in globals():\n",
        "    truncation_estimate.to_csv(EDA_OUTPUT_DIR / \"truncation_estimate.csv\", encoding=\"utf-8\")\n",
        "if \"top_en\" in globals():\n",
        "    top_en.to_csv(EDA_OUTPUT_DIR / \"top_en.csv\", index=False, encoding=\"utf-8\")\n",
        "if \"top_ar\" in globals():\n",
        "    top_ar.to_csv(EDA_OUTPUT_DIR / \"top_ar.csv\", index=False, encoding=\"utf-8\")\n",
        "if \"sample_preview\" in globals():\n",
        "    sample_preview.to_csv(EDA_OUTPUT_DIR / \"sample_preview.csv\", index=False, encoding=\"utf-8\")\n",
        "\n",
        "print(f\"Saved compact EDA artifacts to: {EDA_OUTPUT_DIR}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "id": "ab974ff3",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved parquet: c:\\My Projects\\en-ar-translation\\artifacts\\eda\\final_cleaned_combined_dataset.parquet\n",
            "Saved csv: c:\\My Projects\\en-ar-translation\\artifacts\\eda\\final_cleaned_combined_dataset.csv\n",
            "Saved metadata: c:\\My Projects\\en-ar-translation\\artifacts\\eda\\final_cleaned_combined_dataset_metadata.json\n",
            "Final cleaned rows: 827,576\n"
          ]
        }
      ],
      "source": [
        "# Export full cleaned combined dataset for training reuse\n",
        "EDA_OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "full_dataset_parquet_path = EDA_OUTPUT_DIR / \"final_cleaned_combined_dataset.parquet\"\n",
        "full_dataset_csv_path = EDA_OUTPUT_DIR / \"final_cleaned_combined_dataset.csv\"\n",
        "metadata_path = EDA_OUTPUT_DIR / \"final_cleaned_combined_dataset_metadata.json\"\n",
        "\n",
        "# Parquet is preferred for speed/size; CSV is added for portability.\n",
        "df.to_parquet(full_dataset_parquet_path, index=False)\n",
        "df.to_csv(full_dataset_csv_path, index=False, encoding=\"utf-8\")\n",
        "\n",
        "metadata = {\n",
        "    \"rows\": int(len(df)),\n",
        "    \"columns\": list(df.columns),\n",
        "    \"parquet_path\": str(full_dataset_parquet_path),\n",
        "    \"csv_path\": str(full_dataset_csv_path),\n",
        "    \"max_seq_len_reference\": int(MAX_SEQ_LEN),\n",
        "}\n",
        "pd.Series(metadata).to_json(metadata_path, force_ascii=False, indent=2)\n",
        "\n",
        "print(f\"Saved parquet: {full_dataset_parquet_path}\")\n",
        "print(f\"Saved csv: {full_dataset_csv_path}\")\n",
        "print(f\"Saved metadata: {metadata_path}\")\n",
        "print(f\"Final cleaned rows: {len(df):,}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "147f0ade",
      "metadata": {},
      "source": [
        "## Decision Summary\n",
        "\n",
        "- Final discovery dataset is built from: local 25k CSV + `ds2` + `ds3` (capped) + `ds4` + local `ds5` CSV.\n",
        "- Exact duplicate EN-AR pairs are removed after merge.\n",
        "- Swapped-language rows are detected and corrected (`en`/`ar` swap).\n",
        "- Boundary newline markers are cleaned from both columns.\n",
        "- Arabic diacritics are removed from the Arabic side.\n",
        "- Final cleaned combined dataset is exported for training reuse in `artifacts/eda/final_cleaned_combined_dataset.parquet` (and CSV copy).\n",
        "- EDA artifacts and summaries are exported under `artifacts/eda/`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5972f0d6",
      "metadata": {},
      "source": [
        "## Dataset Credits\n",
        "\n",
        "The combined EN-AR dataset in this project is sourced from the following datasets (in variable order):\n",
        "\n",
        "1. `local_25k` (Kaggle): https://www.kaggle.com/datasets/tahaalselwii/the-arabic-english-sentence-bank-25k?resource=download\n",
        "2. `ds2` (Hugging Face): https://huggingface.co/datasets/Arabic-Clip-Archive/ImageCaptions-7M-Translations-Arabic/viewer/default/train?p=1132\n",
        "3. `ds3` (Hugging Face): https://huggingface.co/datasets/salehalmansour/english-to-arabic-translate\n",
        "4. `ds4` (Hugging Face): https://huggingface.co/datasets/ammagra/english-arabic-speech-translation\n",
        "5. `ds5` (Kaggle): https://www.kaggle.com/datasets/yumnagamal/translation-english-arabic?select=merge_df.csv\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
